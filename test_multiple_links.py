#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test pentru funcÈ›ionalitatea de procesare a multiplelor linkuri
"""

import re
from urllib.parse import urlparse

def extract_urls_from_text(text):
    """
    Extrage toate URL-urile dintr-un text È™i le returneazÄƒ ca listÄƒ.
    DetecteazÄƒ URL-uri cu http/https È™i fÄƒrÄƒ protocol.
    """
    if not text:
        return []
    
    # Pattern pentru URL-uri cu protocol
    url_pattern_with_protocol = r'https?://[^\s]+'
    
    # Pattern pentru URL-uri fÄƒrÄƒ protocol (domenii cunoscute)
    url_pattern_without_protocol = r'(?:^|\s)((?:www\.|m\.|mobile\.)?(?:tiktok\.com|instagram\.com|facebook\.com|twitter\.com|x\.com|threads\.net|pinterest\.com|reddit\.com|vimeo\.com|dailymotion\.com)/[^\s]+)'
    
    urls = []
    
    # GÄƒseÈ™te URL-uri cu protocol
    urls_with_protocol = re.findall(url_pattern_with_protocol, text, re.IGNORECASE)
    urls.extend(urls_with_protocol)
    
    # GÄƒseÈ™te URL-uri fÄƒrÄƒ protocol
    urls_without_protocol = re.findall(url_pattern_without_protocol, text, re.IGNORECASE)
    for url in urls_without_protocol:
        if not url.startswith('http'):
            urls.append('https://' + url)
        else:
            urls.append(url)
    
    # EliminÄƒ duplicatele È™i returneazÄƒ lista
    return list(set(urls))

def test_url_extraction():
    """
    TesteazÄƒ funcÈ›ia de extragere a URL-urilor
    """
    print("ğŸ§ª TESTARE EXTRAGERE URL-URI")
    print("=" * 50)
    
    test_cases = [
        {
            "text": "https://www.tiktok.com/@user/video/123456789",
            "expected_count": 1,
            "description": "Un singur link TikTok cu protocol"
        },
        {
            "text": "Uite videoclipurile: https://www.instagram.com/p/ABC123/ È™i https://www.tiktok.com/@user/video/123",
            "expected_count": 2,
            "description": "DouÄƒ linkuri cu protocol"
        },
        {
            "text": "www.instagram.com/p/ABC123/ tiktok.com/@user/video/123",
            "expected_count": 2,
            "description": "DouÄƒ linkuri fÄƒrÄƒ protocol"
        },
        {
            "text": "Mixte: https://facebook.com/video/123 È™i www.twitter.com/user/status/456 plus reddit.com/r/videos/comments/789",
            "expected_count": 3,
            "description": "Linkuri mixte (cu È™i fÄƒrÄƒ protocol)"
        },
        {
            "text": "Nu conÈ›ine linkuri valide, doar text normal.",
            "expected_count": 0,
            "description": "Text fÄƒrÄƒ linkuri"
        },
        {
            "text": "https://youtube.com/watch?v=123 https://google.com",
            "expected_count": 2,
            "description": "Linkuri nesuportate (ar trebui sÄƒ le detecteze, dar nu le va procesa)"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ Test {i}: {test_case['description']}")
        print(f"ğŸ“„ Text: {test_case['text']}")
        
        urls = extract_urls_from_text(test_case['text'])
        
        print(f"ğŸ” URL-uri gÄƒsite ({len(urls)}):")
        for url in urls:
            print(f"   â€¢ {url}")
        
        if len(urls) == test_case['expected_count']:
            print(f"âœ… SUCCES: GÄƒsite {len(urls)} URL-uri (aÈ™teptat: {test_case['expected_count']})")
        else:
            print(f"âŒ EÈ˜EC: GÄƒsite {len(urls)} URL-uri (aÈ™teptat: {test_case['expected_count']})")

def simulate_supported_url_check(url):
    """
    SimuleazÄƒ funcÈ›ia is_supported_url pentru test
    """
    supported_domains = [
        'tiktok.com', 'instagram.com', 'facebook.com', 
        'twitter.com', 'x.com', 'threads.net', 
        'pinterest.com', 'reddit.com', 'vimeo.com', 'dailymotion.com'
    ]
    
    for domain in supported_domains:
        if domain in url.lower():
            return True
    return False

def filter_supported_urls(urls):
    """
    FiltreazÄƒ doar URL-urile suportate din lista datÄƒ.
    """
    supported_urls = []
    for url in urls:
        if simulate_supported_url_check(url):
            supported_urls.append(url)
    return supported_urls

def test_complete_workflow():
    """
    TesteazÄƒ workflow-ul complet de procesare
    """
    print("\n\nğŸ”„ TESTARE WORKFLOW COMPLET")
    print("=" * 50)
    
    test_messages = [
        "Uite videoclipurile mele: https://www.tiktok.com/@user1/video/123 https://www.instagram.com/p/ABC123/ https://youtube.com/watch?v=456",
        "www.facebook.com/video/789 È™i reddit.com/r/videos/comments/101112",
        "Un singur link: https://vimeo.com/123456789",
        "Text fÄƒrÄƒ linkuri valide"
    ]
    
    for i, message in enumerate(test_messages, 1):
        print(f"\nğŸ“± Mesaj {i}: {message[:60]}{'...' if len(message) > 60 else ''}")
        
        # Extrage toate URL-urile
        all_urls = extract_urls_from_text(message)
        print(f"ğŸ” URL-uri detectate: {len(all_urls)}")
        
        # FiltreazÄƒ URL-urile suportate
        supported_urls = filter_supported_urls(all_urls)
        print(f"âœ… URL-uri suportate: {len(supported_urls)}")
        
        if supported_urls:
            if len(supported_urls) > 1:
                print(f"ğŸ¯ Procesare multiplÄƒ: {len(supported_urls)} videoclipuri")
                print(f"â±ï¸ Timp estimat: ~{len(supported_urls) * 10} secunde")
            else:
                print(f"ğŸ“± Procesare simplÄƒ: 1 videoclip")
            
            for j, url in enumerate(supported_urls, 1):
                print(f"   {j}. {url}")
        else:
            if all_urls:
                print(f"âŒ URL-uri nesuportate gÄƒsite: {len(all_urls)}")
            else:
                print(f"âŒ Niciun URL gÄƒsit")

if __name__ == "__main__":
    test_url_extraction()
    test_complete_workflow()
    
    print("\n\nğŸ‰ TESTARE COMPLETÄ‚!")
    print("\nğŸ’¡ Pentru a testa cu bot-ul real:")
    print("   1. Trimite un mesaj cu multiple linkuri")
    print("   2. Bot-ul va detecta automat toate linkurile")
    print("   3. Va procesa fiecare cu o pauzÄƒ de 3 secunde")
    print("   4. Va afiÈ™a progresul È™i raportul final")