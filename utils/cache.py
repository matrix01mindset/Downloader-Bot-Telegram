import time
import json
import hashlib
import logging
import threading
import asyncio
import os
import pickle
import tempfile
import weakref
from typing import Dict, Any, Optional, Union, List, Callable, TypeVar, Generic
from dataclasses import dataclass
from enum import Enum
from collections import OrderedDict, defaultdict

try:
    from utils.config import config
    from utils.memory_manager import memory_manager, MemoryPriority
    from utils.monitoring import monitoring
except ImportError:
    config = None
    memory_manager = None
    monitoring = None

import sys

logger = logging.getLogger(__name__)

T = TypeVar('T')

class CacheStrategy(Enum):
    """Strategii de cache disponibile"""
    LRU = "lru"              # Least Recently Used
    LFU = "lfu"              # Least Frequently Used  
    TTL = "ttl"              # Time To Live
    FIFO = "fifo"            # First In First Out
    SMART = "smart"          # Strategie inteligentÄƒ combinatÄƒ

class CacheTier(Enum):
    """Niveluri de cache"""
    MEMORY = "memory"        # Cache Ã®n memorie (rapid)
    DISK = "disk"           # Cache pe disk (persistent)
    HYBRID = "hybrid"       # CombinaÈ›ie memory + disk

@dataclass
class CacheEntry:
    """Intrare Ã®n cache cu metadata completÄƒ"""
    key: str
    value: Any
    created_at: float
    last_accessed: float
    access_count: int
    ttl: Optional[float]
    size_bytes: int
    metadata: Dict[str, Any]
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    @property
    def is_expired(self) -> bool:
        """VerificÄƒ dacÄƒ intrarea a expirat"""
        if self.ttl is None:
            return False
        return (time.time() - self.created_at) > self.ttl
    
    @property
    def age_seconds(self) -> float:
        """VÃ¢rsta intrÄƒrii Ã®n secunde"""
        return time.time() - self.created_at

class LRUCache(Generic[T]):
    """Cache LRU optimizat cu TTL È™i statistici"""
    
    def __init__(self, max_size: int = 1000, ttl: Optional[float] = None):
        self.max_size = max_size
        self.default_ttl = ttl
        self.cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self.lock = threading.RLock()
        self.stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'expired_removals': 0
        }
    
    def get(self, key: str) -> Optional[T]:
        """ObÈ›ine valoare din cache"""
        with self.lock:
            if key not in self.cache:
                self.stats['misses'] += 1
                return None
            
            entry = self.cache[key]
            
            # VerificÄƒ expirarea
            if entry.is_expired:
                del self.cache[key]
                self.stats['expired_removals'] += 1
                self.stats['misses'] += 1
                return None
            
            # ActualizeazÄƒ statistici de acces
            entry.last_accessed = time.time()
            entry.access_count += 1
            
            # MutÄƒ la sfÃ¢rÈ™itul listei (most recently used)
            self.cache.move_to_end(key)
            
            self.stats['hits'] += 1
            return entry.value
    
    def put(self, key: str, value: T, ttl: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """AdaugÄƒ valoare Ã®n cache"""
        with self.lock:
            current_time = time.time()
            effective_ttl = ttl if ttl is not None else self.default_ttl
            
            # CalculeazÄƒ dimensiunea aproximativÄƒ
            try:
                size_bytes = sys.getsizeof(value) + sys.getsizeof(key)
            except:
                size_bytes = 1024  # Estimare default
            
            # CreeazÄƒ intrarea
            entry = CacheEntry(
                key=key,
                value=value,
                created_at=current_time,
                last_accessed=current_time,
                access_count=1,
                ttl=effective_ttl,
                size_bytes=size_bytes,
                metadata=metadata or {}
            )
            
            # DacÄƒ cheia existÄƒ deja, actualizeazÄƒ
            if key in self.cache:
                self.cache[key] = entry
                self.cache.move_to_end(key)
                return True
            
            # VerificÄƒ dacÄƒ trebuie sÄƒ elimine intrÄƒri
            while len(self.cache) >= self.max_size:
                oldest_key, _ = self.cache.popitem(last=False)
                self.stats['evictions'] += 1
                logger.debug(f"ðŸ—‘ï¸ Evicted cache entry: {oldest_key}")
            
            # AdaugÄƒ noua intrare
            self.cache[key] = entry
            return True
    
    def remove(self, key: str) -> bool:
        """EliminÄƒ o cheie din cache"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
                return True
            return False
    
    def clear(self):
        """CurÄƒÈ›Äƒ Ã®ntregul cache"""
        with self.lock:
            self.cache.clear()
            self.stats = {
                'hits': 0,
                'misses': 0,
                'evictions': 0,
                'expired_removals': 0
            }
    
    def cleanup_expired(self) -> int:
        """CurÄƒÈ›Äƒ intrÄƒrile expirate"""
        with self.lock:
            current_time = time.time()
            expired_keys = []
            
            for key, entry in self.cache.items():
                if entry.is_expired:
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self.cache[key]
                self.stats['expired_removals'] += 1
            
            if expired_keys:
                logger.debug(f"ðŸ§¹ Removed {len(expired_keys)} expired entries")
            
            return len(expired_keys)
    
    def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici cache"""
        with self.lock:
            total_requests = self.stats['hits'] + self.stats['misses']
            hit_rate = (self.stats['hits'] / total_requests * 100) if total_requests > 0 else 0
            
            return {
                'entries': len(self.cache),
                'max_size': self.max_size,
                'hit_rate_percent': round(hit_rate, 2),
                'hits': self.stats['hits'],
                'misses': self.stats['misses'],
                'evictions': self.stats['evictions'],
                'expired_removals': self.stats['expired_removals']
            }

class DiskCache:
    """Cache persistent pe disk cu compresie È™i indexare"""
    
    def __init__(self, cache_dir: Optional[str] = None, max_size_mb: int = 50):
        if cache_dir is None:
            cache_dir = os.path.join(tempfile.gettempdir(), "telegram_bot_cache")
        
        self.cache_dir = cache_dir
        self.max_size_bytes = max_size_mb * 1024 * 1024
        self.index_file = os.path.join(cache_dir, "cache_index.json")
        
        # CreeazÄƒ directorul dacÄƒ nu existÄƒ
        os.makedirs(cache_dir, exist_ok=True)
        
        # ÃŽncarcÄƒ indexul
        self.index = self._load_index()
        self.lock = threading.RLock()
    
    def _load_index(self) -> Dict[str, Dict[str, Any]]:
        """ÃŽncarcÄƒ indexul cache-ului de pe disk"""
        try:
            if os.path.exists(self.index_file):
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ Could not load cache index: {e}")
        return {}
    
    def _save_index(self):
        """SalveazÄƒ indexul pe disk"""
        try:
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.index, f, indent=2)
        except Exception as e:
            logger.error(f"âŒ Could not save cache index: {e}")
    
    def _get_cache_file_path(self, key: str) -> str:
        """GenereazÄƒ calea fiÈ™ierului pentru o cheie"""
        safe_key = hashlib.sha256(key.encode('utf-8')).hexdigest()
        return os.path.join(self.cache_dir, f"{safe_key}.cache")
    
    def get(self, key: str) -> Optional[Any]:
        """ObÈ›ine valoare din cache-ul de pe disk"""
        with self.lock:
            if key not in self.index:
                return None
            
            entry_info = self.index[key]
            
            # VerificÄƒ expirarea
            if entry_info.get('ttl') and time.time() - entry_info['created_at'] > entry_info['ttl']:
                self.remove(key)
                return None
            
            # ÃŽncarcÄƒ valoarea de pe disk
            cache_file = self._get_cache_file_path(key)
            try:
                if os.path.exists(cache_file):
                    with open(cache_file, 'rb') as f:
                        value = pickle.load(f)
                    
                    # ActualizeazÄƒ statistici
                    entry_info['last_accessed'] = time.time()
                    entry_info['access_count'] = entry_info.get('access_count', 0) + 1
                    self._save_index()
                    
                    return value
                else:
                    # FiÈ™ierul nu existÄƒ, eliminÄƒ din index
                    del self.index[key]
                    self._save_index()
                    return None
            except Exception as e:
                logger.error(f"âŒ Error loading from disk cache: {e}")
                self.remove(key)
                return None
    
    def put(self, key: str, value: Any, ttl: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """SalveazÄƒ valoare Ã®n cache-ul de pe disk"""
        with self.lock:
            try:
                cache_file = self._get_cache_file_path(key)
                
                # SalveazÄƒ valoarea
                with open(cache_file, 'wb') as f:
                    pickle.dump(value, f)
                
                # CalculeazÄƒ dimensiunea
                file_size = os.path.getsize(cache_file)
                
                # ActualizeazÄƒ indexul
                current_time = time.time()
                self.index[key] = {
                    'created_at': current_time,
                    'last_accessed': current_time,
                    'access_count': 1,
                    'ttl': ttl,
                    'size_bytes': file_size,
                    'metadata': metadata or {},
                    'file_path': cache_file
                }
                
                # VerificÄƒ dimensiunea totalÄƒ È™i curÄƒÈ›Äƒ dacÄƒ e necesar
                total_size = self._get_total_size()
                if total_size > self.max_size_bytes:
                    self._cleanup_lru(total_size - self.max_size_bytes)
                
                self._save_index()
                return True
                
            except Exception as e:
                logger.error(f"âŒ Error saving to disk cache: {e}")
                return False
    
    def remove(self, key: str) -> bool:
        """EliminÄƒ o intrare din cache"""
        with self.lock:
            if key not in self.index:
                return False
            
            try:
                # È˜terge fiÈ™ierul
                cache_file = self._get_cache_file_path(key)
                if os.path.exists(cache_file):
                    os.remove(cache_file)
                
                # EliminÄƒ din index
                del self.index[key]
                self._save_index()
                return True
                
            except Exception as e:
                logger.error(f"âŒ Error removing from disk cache: {e}")
                return False
    
    def _get_total_size(self) -> int:
        """CalculeazÄƒ dimensiunea totalÄƒ a cache-ului"""
        return sum(entry.get('size_bytes', 0) for entry in self.index.values())
    
    def _cleanup_lru(self, needed_space: int):
        """CurÄƒÈ›Äƒ intrÄƒrile mai puÈ›in folosite recent"""
        # SorteazÄƒ dupÄƒ last_accessed
        entries = list(self.index.items())
        entries.sort(key=lambda x: x[1].get('last_accessed', 0))
        
        freed_space = 0
        for key, entry_info in entries:
            if freed_space >= needed_space:
                break
            
            freed_space += entry_info.get('size_bytes', 0)
            self.remove(key)
            logger.debug(f"ðŸ—‘ï¸ Removed LRU disk cache entry: {key}")
    
    def cleanup_expired(self) -> int:
        """CurÄƒÈ›Äƒ intrÄƒrile expirate"""
        with self.lock:
            current_time = time.time()
            expired_keys = []
            
            for key, entry_info in self.index.items():
                ttl = entry_info.get('ttl')
                if ttl and (current_time - entry_info['created_at']) > ttl:
                    expired_keys.append(key)
            
            for key in expired_keys:
                self.remove(key)
            
            if expired_keys:
                logger.debug(f"ðŸ§¹ Removed {len(expired_keys)} expired disk entries")
            
            return len(expired_keys)
    
    def clear(self):
        """CurÄƒÈ›Äƒ Ã®ntregul cache de pe disk"""
        with self.lock:
            for key in list(self.index.keys()):
                self.remove(key)
    
    def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici cache disk"""
        with self.lock:
            total_size = self._get_total_size()
            
            return {
                'entries': len(self.index),
                'total_size_bytes': total_size,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'max_size_mb': round(self.max_size_bytes / (1024 * 1024), 2),
                'usage_percent': round((total_size / self.max_size_bytes) * 100, 2) if self.max_size_bytes > 0 else 0
            }

class SmartCache(Generic[T]):
    """Cache inteligent cu strategie adaptivÄƒ È™i management automat"""
    
    def __init__(self, 
                 memory_cache_size: int = 500,
                 disk_cache_size_mb: int = 50,
                 default_ttl: Optional[float] = 3600,  # 1 orÄƒ
                 strategy: CacheStrategy = CacheStrategy.SMART):
        
        self.strategy = strategy
        self.default_ttl = default_ttl
        self.memory_cache = LRUCache[T](max_size=memory_cache_size, ttl=default_ttl)
        self.disk_cache = DiskCache(max_size_mb=disk_cache_size_mb)
        
        # Statistici globale
        self.stats = {
            'total_requests': 0,
            'memory_hits': 0,
            'disk_hits': 0,
            'misses': 0
        }
        
        # Background cleanup
        self.cleanup_thread: Optional[threading.Thread] = None
        self.should_stop = False
        self.cleanup_interval = 300  # 5 minute
        
        # Configurare avansatÄƒ
        if config:
            self._start_cleanup_thread()
            logger.info("ðŸ§  Smart Cache initialized with advanced features")
    
    def get(self, key: str) -> Optional[T]:
        """ObÈ›ine valoare din cache cu strategie inteligentÄƒ"""
        self.stats['total_requests'] += 1
        
        # ÃŽncearcÄƒ memoria mai Ã®ntÃ¢i
        value = self.memory_cache.get(key)
        if value is not None:
            self.stats['memory_hits'] += 1
            return value
        
        # ÃŽncearcÄƒ disk-ul
        value = self.disk_cache.get(key)
        if value is not None:
            self.stats['disk_hits'] += 1
            # PromoveazÄƒ Ã®n memorie pentru acces rapid viitor
            self._promote_to_memory(key, value)
            return value
        
        self.stats['misses'] += 1
        return None
    
    def put(self, key: str, 
            value: T, 
            ttl: Optional[float] = None,
            priority: str = "normal",
            metadata: Optional[Dict[str, Any]] = None) -> bool:
        """AdaugÄƒ valoare Ã®n cache cu strategie optimizatÄƒ"""
        
        effective_ttl = ttl if ttl is not None else self.default_ttl
        cache_metadata = metadata or {}
        cache_metadata['priority'] = priority
        
        # CalculeazÄƒ dimensiunea aproximativÄƒ
        try:
            value_size = sys.getsizeof(value)
        except:
            value_size = 1024
        
        # Strategie de plasare
        if self.strategy == CacheStrategy.SMART:
            return self._smart_put(key, value, effective_ttl, value_size, cache_metadata)
        elif self.strategy == CacheStrategy.LRU:
            return self.memory_cache.put(key, value, effective_ttl, cache_metadata)
        else:
            # Pentru alte strategii, foloseÈ™te memoria
            success = self.memory_cache.put(key, value, effective_ttl, cache_metadata)
            if memory_manager:
                memory_manager.track_allocation(value_size, MemoryPriority.NORMAL)
            return success
    
    def _smart_put(self, key: str, value: T, ttl: float, value_size: int, metadata: Dict[str, Any]) -> bool:
        """Strategie inteligentÄƒ de plasare Ã®n cache"""
        # Obiecte mici È™i frecvent accesate -> memorie
        if value_size < 10240:  # < 10KB
            return self.memory_cache.put(key, value, ttl, metadata)
        else:
            # Obiecte mari -> disk
            return self.disk_cache.put(key, value, ttl, metadata)
    
    def _promote_to_memory(self, key: str, value: T):
        """PromoveazÄƒ o valoare din disk Ã®n memorie"""
        if len(self.memory_cache.cache) < self.memory_cache.max_size:
            try:
                self.memory_cache.put(key, value)
            except Exception as e:
                logger.debug(f"Could not promote to memory: {e}")
    
    def remove(self, key: str) -> bool:
        """EliminÄƒ din ambele cache-uri"""
        memory_removed = self.memory_cache.remove(key)
        disk_removed = self.disk_cache.remove(key)
        
        if memory_manager and (memory_removed or disk_removed):
            memory_manager.release_allocation(1024)  # Estimare
        
        return memory_removed or disk_removed
    
    def clear(self):
        """CurÄƒÈ›Äƒ ambele cache-uri"""
        self.memory_cache.clear()
        self.disk_cache.clear()
        self.stats = {
            'total_requests': 0,
            'memory_hits': 0,
            'disk_hits': 0,
            'misses': 0
        }
    
    def _start_cleanup_thread(self):
        """PorneÈ™te thread-ul de curÄƒÈ›are automatÄƒ"""
        if self.cleanup_thread is None:
            self.cleanup_thread = threading.Thread(
                target=self._cleanup_loop,
                daemon=True,
                name="CacheCleanup"
            )
            self.cleanup_thread.start()
    
    def _cleanup_loop(self):
        """Loop de curÄƒÈ›are automatÄƒ"""
        while not self.should_stop:
            try:
                # CurÄƒÈ›Äƒ intrÄƒrile expirate
                self.memory_cache.cleanup_expired()
                self.disk_cache.cleanup_expired()
                
                logger.debug("ðŸ§¹ Cache cleanup completed")
                
                # VerificÄƒ memoria dacÄƒ e disponibil memory_manager
                if memory_manager:
                    memory_status = asyncio.run(memory_manager.get_memory_status())
                    if memory_status.get('usage_percent', 0) > 85:
                        self._aggressive_cleanup()
                
                time.sleep(self.cleanup_interval)
                
            except Exception as e:
                logger.error(f"âŒ Cache cleanup error: {e}")
                time.sleep(60)  # Retry dupÄƒ 1 minut
    
    def _aggressive_cleanup(self):
        """CurÄƒÈ›are agresivÄƒ cÃ¢nd memoria e plinÄƒ"""
        logger.warning("âš¡ Starting aggressive cache cleanup")
        
        # Reduce temporar dimensiunea cache-ului de memorie
        original_size = self.memory_cache.max_size
        self.memory_cache.max_size = max(50, original_size // 2)
        
        # EliminÄƒ intrÄƒrile mai puÈ›in folosite
        with self.memory_cache.lock:
            # SorteazÄƒ dupÄƒ access_count È™i eliminÄƒ jumÄƒtate
            entries = list(self.memory_cache.cache.items())
            entries.sort(key=lambda x: x[1].access_count)
            
            to_remove = entries[:len(entries)//2]
            for key, _ in to_remove:
                self.memory_cache.cache.pop(key, None)
                
        logger.warning(f"âš¡ Aggressive cache cleanup: reduced from {original_size} to {self.memory_cache.max_size}")
        
        # RestaureazÄƒ dimensiunea dupÄƒ 5 minute
        def restore_size():
            time.sleep(300)
            self.memory_cache.max_size = original_size
            
        threading.Thread(target=restore_size, daemon=True).start()
        
    async def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici complete ale cache-ului"""
        
        memory_stats = self.memory_cache.get_stats()
        disk_stats = self.disk_cache.get_stats()
        
        total_requests = self.stats['total_requests']
        overall_hit_rate = 0
        
        if total_requests > 0:
            total_hits = self.stats['memory_hits'] + self.stats['disk_hits']
            overall_hit_rate = (total_hits / total_requests) * 100
            
        return {
            "strategy": self.strategy.value,
            "overall": {
                "hit_rate_percent": round(overall_hit_rate, 2),
                "total_requests": total_requests,
                "memory_hits": self.stats['memory_hits'],
                "disk_hits": self.stats['disk_hits'],
                "misses": self.stats['misses'],
                "memory_hit_rate": round((self.stats['memory_hits'] / total_requests * 100) if total_requests > 0 else 0, 2),
                "disk_hit_rate": round((self.stats['disk_hits'] / total_requests * 100) if total_requests > 0 else 0, 2)
            },
            "memory_cache": memory_stats,
            "disk_cache": disk_stats,
            "health": {
                "cleanup_thread_alive": self.cleanup_thread.is_alive() if self.cleanup_thread else False,
                "total_entries": memory_stats.get('entries', 0) + disk_stats.get('entries', 0)
            }
        }
        
    def stop(self):
        """OpreÈ™te cache-ul È™i cleanup thread"""
        self.should_stop = True
        if self.cleanup_thread and self.cleanup_thread.is_alive():
            self.cleanup_thread.join(timeout=5)
            
        logger.info("ðŸ§  Smart Cache stopped")

# Helper functions pentru cache keys
def generate_cache_key(prefix: str, *args, **kwargs) -> str:
    """GenereazÄƒ o cheie de cache consistentÄƒ"""
    
    # CombinÄƒ argumentele Ã®ntr-un string
    key_parts = [prefix]
    key_parts.extend(str(arg) for arg in args)
    
    # AdaugÄƒ kwargs sortate
    for k, v in sorted(kwargs.items()):
        key_parts.append(f"{k}={v}")
        
    key_string = "|".join(key_parts)
    
    # Hash pentru lungime consistentÄƒ
    return hashlib.sha256(key_string.encode('utf-8')).hexdigest()[:32]

# Cache decorator
def cached(ttl: Optional[float] = None, 
          key_prefix: str = "default",
          priority: str = "normal"):
    """
    Decorator pentru cache automat
    
    Usage:
        @cached(ttl=3600, key_prefix="video_metadata")
        def get_video_info(url):
            # expensive operation
            return video_info
    """
    def decorator(func):
        if asyncio.iscoroutinefunction(func):
            async def async_wrapper(*args, **kwargs):
                # GenereazÄƒ cheia cache
                cache_key = generate_cache_key(f"{key_prefix}_{func.__name__}", *args, **kwargs)
                
                # ÃŽncearcÄƒ sÄƒ obÈ›ii din cache
                cached_result = cache.get(cache_key)
                if cached_result is not None:
                    return cached_result
                    
                # ExecutÄƒ funcÈ›ia
                result = await func(*args, **kwargs)
                
                # SalveazÄƒ Ã®n cache
                if result is not None:
                    cache.put(cache_key, result, ttl=ttl, priority=priority)
                    
                return result
            return async_wrapper
        else:
            def sync_wrapper(*args, **kwargs):
                # GenereazÄƒ cheia cache
                cache_key = generate_cache_key(f"{key_prefix}_{func.__name__}", *args, **kwargs)
                
                # ÃŽncearcÄƒ sÄƒ obÈ›ii din cache
                cached_result = cache.get(cache_key)
                if cached_result is not None:
                    return cached_result
                    
                # ExecutÄƒ funcÈ›ia
                result = func(*args, **kwargs)
                
                # SalveazÄƒ Ã®n cache
                if result is not None:
                    cache.put(cache_key, result, ttl=ttl, priority=priority)
                    
                return result
            return sync_wrapper
    return decorator

# Singleton instance
cache = SmartCache[Any](
    memory_cache_size=500,
    disk_cache_size_mb=50,
    default_ttl=3600,  # 1 orÄƒ
    strategy=CacheStrategy.SMART
)
