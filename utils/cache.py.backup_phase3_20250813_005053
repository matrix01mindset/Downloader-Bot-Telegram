# utils/cache.py - Sistema de Cache inteligent pentru Free Tier
# Versiunea: 2.0.0 - Arhitectura ModularÄƒ

import time
import json
import hashlib
import logging
import threading
import asyncio
import os
import pickle
import tempfile
import weakref
from typing import Dict, Any, Optional, Union, List, Callable, TypeVar, Generic
from dataclasses import dataclass
from enum import Enum
from collections import OrderedDict, defaultdict

try:
    from utils.config import config
    from utils.memory_manager import memory_manager, MemoryPriority
    from utils.monitoring import monitoring
except ImportError:
    config = None
    memory_manager = None
    monitoring = None

logger = logging.getLogger(__name__)

T = TypeVar('T')

class CacheStrategy(Enum):
    """Strategii de cache disponibile"""
    LRU = "lru"              # Least Recently Used
    LFU = "lfu"              # Least Frequently Used  
    TTL = "ttl"              # Time To Live
    FIFO = "fifo"            # First In First Out
    SMART = "smart"          # Strategie inteligentÄƒ combinatÄƒ

class CacheTier(Enum):
    """Niveluri de cache"""
    MEMORY = "memory"        # Cache Ã®n memorie (rapid)
    DISK = "disk"           # Cache pe disk (persistent)
    HYBRID = "hybrid"       # CombinaÈ›ie memory + disk

@dataclass
class CacheEntry:
    """Intrarea din cache"""
    key: str
    value: Any
    created_at: float
    last_accessed: float
    access_count: int
    ttl: Optional[float]
    size_bytes: int
    metadata: Dict[str, Any]
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
            
    @property
    def is_expired(self) -> bool:
        """VerificÄƒ dacÄƒ intrarea a expirat"""
        if self.ttl is None:
            return False
        return time.time() - self.created_at > self.ttl
        
    @property
    def age_seconds(self) -> float:
        """VÃ¢rsta intrÄƒrii Ã®n secunde"""
        return time.time() - self.created_at

class LRUCache(Generic[T]):
    """Cache LRU optimizat pentru memorie"""
    
    def __init__(self, max_size: int = 1000, ttl: Optional[float] = None):
        self.max_size = max_size
        self.ttl = ttl
        self.cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self.lock = threading.RLock()
        self._hits = 0
        self._misses = 0
        
    def get(self, key: str) -> Optional[T]:
        """ObÈ›ine o valoare din cache"""
        with self.lock:
            if key not in self.cache:
                self._misses += 1
                if monitoring:
                    monitoring.record_cache_event("get", hit=False)
                return None
                
            entry = self.cache[key]
            
            # VerificÄƒ expirarea
            if entry.is_expired:
                del self.cache[key]
                self._misses += 1
                if monitoring:
                    monitoring.record_cache_event("get", hit=False)
                return None
                
            # ActualizeazÄƒ statisticile
            entry.last_accessed = time.time()
            entry.access_count += 1
            
            # MutÄƒ la sfÃ¢rÈ™itul OrderedDict (cel mai recent folosit)
            self.cache.move_to_end(key)
            
            self._hits += 1
            if monitoring:
                monitoring.record_cache_event("get", hit=True)
                
            return entry.value
            
    def put(self, key: str, value: T, ttl: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """Pune o valoare Ã®n cache"""
        with self.lock:
            current_time = time.time()
            
            # CalculeazÄƒ dimensiunea aproximativÄƒ
            try:
                size_bytes = len(str(value).encode('utf-8'))
            except:
                size_bytes = 1024  # Estimare default
                
            # FoloseÈ™te TTL-ul specificat sau cel default
            effective_ttl = ttl or self.ttl
            
            # CreeazÄƒ intrarea
            entry = CacheEntry(
                key=key,
                value=value,
                created_at=current_time,
                last_accessed=current_time,
                access_count=1,
                ttl=effective_ttl,
                size_bytes=size_bytes,
                metadata=metadata or {}
            )
            
            # DacÄƒ cheia existÄƒ deja, o actualizeazÄƒ
            if key in self.cache:
                self.cache[key] = entry
                self.cache.move_to_end(key)
                return True
                
            # VerificÄƒ dacÄƒ avem loc
            if len(self.cache) >= self.max_size:
                # EliminÄƒ intrarea cea mai puÈ›in recent folositÄƒ
                oldest_key = next(iter(self.cache))
                removed_entry = self.cache.pop(oldest_key)
                logger.debug(f"ðŸ§¹ Evicted LRU cache entry: {oldest_key}")
                
            # AdaugÄƒ noua intrare
            self.cache[key] = entry
            
            if monitoring:
                monitoring.record_cache_event("put")
                
            return True
            
    def remove(self, key: str) -> bool:
        """EliminÄƒ o intrare din cache"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
                if monitoring:
                    monitoring.record_cache_event("remove")
                return True
            return False
            
    def clear(self):
        """CurÄƒÈ›Äƒ tot cache-ul"""
        with self.lock:
            self.cache.clear()
            self._hits = 0
            self._misses = 0
            
    def cleanup_expired(self) -> int:
        """CurÄƒÈ›Äƒ intrarile expirate"""
        with self.lock:
            current_time = time.time()
            expired_keys = []
            
            for key, entry in self.cache.items():
                if entry.is_expired:
                    expired_keys.append(key)
                    
            for key in expired_keys:
                del self.cache[key]
                
            if expired_keys and monitoring:
                monitoring.record_cache_event("cleanup_expired")
                
            return len(expired_keys)
            
    def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici cache"""
        with self.lock:
            total_requests = self._hits + self._misses
            hit_rate = (self._hits / total_requests * 100) if total_requests > 0 else 0
            
            total_size = sum(entry.size_bytes for entry in self.cache.values())
            
            return {
                "entries": len(self.cache),
                "max_size": self.max_size,
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate_percent": round(hit_rate, 2),
                "total_size_bytes": total_size,
                "avg_size_bytes": total_size // len(self.cache) if self.cache else 0
            }

class DiskCache:
    """Cache persistent pe disk"""
    
    def __init__(self, cache_dir: Optional[str] = None, max_size_mb: int = 50):
        self.cache_dir = cache_dir or os.path.join(tempfile.gettempdir(), "video_bot_cache")
        self.max_size_mb = max_size_mb
        self.max_size_bytes = max_size_mb * 1024 * 1024
        
        # CreeazÄƒ directorul de cache
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # Index pentru quick lookup
        self.index_file = os.path.join(self.cache_dir, "cache_index.json")
        self.index: Dict[str, Dict[str, Any]] = self._load_index()
        self.lock = threading.RLock()
        
        logger.info(f"ðŸ’¾ Disk cache initialized: {self.cache_dir} (max: {max_size_mb}MB)")
        
    def _load_index(self) -> Dict[str, Dict[str, Any]]:
        """ÃŽncarcÄƒ indexul cache-ului"""
        try:
            if os.path.exists(self.index_file):
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ Could not load cache index: {e}")
            
        return {}
        
    def _save_index(self):
        """SalveazÄƒ indexul cache-ului"""
        try:
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.index, f, indent=2)
        except Exception as e:
            logger.warning(f"âš ï¸ Could not save cache index: {e}")
            
    def _get_cache_file_path(self, key: str) -> str:
        """GenereazÄƒ calea fiÈ™ierului pentru o cheie"""
        # Hash-ul cheii pentru nume de fiÈ™ier sigur
        key_hash = hashlib.md5(key.encode('utf-8')).hexdigest()
        return os.path.join(self.cache_dir, f"cache_{key_hash}.pkl")
        
    def get(self, key: str) -> Optional[Any]:
        """ObÈ›ine o valoare din cache"""
        with self.lock:
            if key not in self.index:
                return None
                
            entry_info = self.index[key]
            
            # VerificÄƒ expirarea
            if entry_info.get('ttl') and time.time() - entry_info['created_at'] > entry_info['ttl']:
                self.remove(key)
                return None
                
            # ÃŽncearcÄƒ sÄƒ Ã®ncarce fiÈ™ierul
            cache_file = self._get_cache_file_path(key)
            
            try:
                if os.path.exists(cache_file):
                    with open(cache_file, 'rb') as f:
                        value = pickle.load(f)
                        
                    # ActualizeazÄƒ statisticile Ã®n index
                    entry_info['last_accessed'] = time.time()
                    entry_info['access_count'] = entry_info.get('access_count', 0) + 1
                    self._save_index()
                    
                    if monitoring:
                        monitoring.record_cache_event("disk_get", hit=True)
                        
                    return value
                else:
                    # FiÈ™ierul lipseÈ™te, È™terge din index
                    self.remove(key)
                    return None
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Error loading cache file {cache_file}: {e}")
                self.remove(key)
                return None
                
    def put(self, key: str, value: Any, ttl: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """Pune o valoare Ã®n cache"""
        with self.lock:
            cache_file = self._get_cache_file_path(key)
            
            try:
                # SalveazÄƒ valoarea
                with open(cache_file, 'wb') as f:
                    pickle.dump(value, f)
                    
                # ObÈ›ine dimensiunea fiÈ™ierului
                file_size = os.path.getsize(cache_file)
                
                # VerificÄƒ dacÄƒ depÄƒÈ™im limita de dimensiune
                if self._get_total_size() + file_size > self.max_size_bytes:
                    # Cleanup bazat pe LRU
                    self._cleanup_lru(file_size)
                    
                # ActualizeazÄƒ indexul
                current_time = time.time()
                self.index[key] = {
                    'created_at': current_time,
                    'last_accessed': current_time,
                    'access_count': 1,
                    'ttl': ttl,
                    'size_bytes': file_size,
                    'file_path': cache_file,
                    'metadata': metadata or {}
                }
                
                self._save_index()
                
                if monitoring:
                    monitoring.record_cache_event("disk_put")
                    
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ Error saving cache file {cache_file}: {e}")
                # È˜terge fiÈ™ierul parÈ›ial dacÄƒ existÄƒ
                if os.path.exists(cache_file):
                    try:
                        os.remove(cache_file)
                    except:
                        pass
                return False
                
    def remove(self, key: str) -> bool:
        """EliminÄƒ o intrare din cache"""
        with self.lock:
            if key not in self.index:
                return False
                
            entry_info = self.index[key]
            cache_file = entry_info.get('file_path') or self._get_cache_file_path(key)
            
            # È˜terge fiÈ™ierul
            try:
                if os.path.exists(cache_file):
                    os.remove(cache_file)
            except Exception as e:
                logger.warning(f"âš ï¸ Error removing cache file {cache_file}: {e}")
                
            # È˜terge din index
            del self.index[key]
            self._save_index()
            
            if monitoring:
                monitoring.record_cache_event("disk_remove")
                
            return True
            
    def _get_total_size(self) -> int:
        """CalculeazÄƒ dimensiunea totalÄƒ a cache-ului"""
        return sum(entry.get('size_bytes', 0) for entry in self.index.values())
        
    def _cleanup_lru(self, needed_space: int):
        """CurÄƒÈ›Äƒ cache-ul bazat pe LRU pentru a face loc"""
        # SorteazÄƒ entrÄƒrile dupÄƒ last_accessed
        sorted_entries = sorted(
            self.index.items(),
            key=lambda x: x[1].get('last_accessed', 0)
        )
        
        freed_space = 0
        for key, entry_info in sorted_entries:
            if freed_space >= needed_space:
                break
                
            file_size = entry_info.get('size_bytes', 0)
            if self.remove(key):
                freed_space += file_size
                logger.debug(f"ðŸ§¹ Evicted disk cache entry: {key}")
                
    def cleanup_expired(self) -> int:
        """CurÄƒÈ›Äƒ intrarile expirate"""
        with self.lock:
            current_time = time.time()
            expired_keys = []
            
            for key, entry_info in self.index.items():
                ttl = entry_info.get('ttl')
                if ttl and current_time - entry_info['created_at'] > ttl:
                    expired_keys.append(key)
                    
            for key in expired_keys:
                self.remove(key)
                
            return len(expired_keys)
            
    def clear(self):
        """CurÄƒÈ›Äƒ tot cache-ul"""
        with self.lock:
            # È˜terge toate fiÈ™ierele
            for entry_info in self.index.values():
                cache_file = entry_info.get('file_path')
                if cache_file and os.path.exists(cache_file):
                    try:
                        os.remove(cache_file)
                    except:
                        pass
                        
            # CurÄƒÈ›Äƒ indexul
            self.index.clear()
            self._save_index()
            
    def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici cache"""
        with self.lock:
            total_size = self._get_total_size()
            
            return {
                "entries": len(self.index),
                "total_size_bytes": total_size,
                "total_size_mb": round(total_size / (1024 * 1024), 2),
                "max_size_mb": self.max_size_mb,
                "utilization_percent": round((total_size / self.max_size_bytes) * 100, 2),
                "cache_dir": self.cache_dir
            }

class SmartCache(Generic[T]):
    """
    Cache inteligent cu strategie adaptivÄƒ pentru Free Tier
    
    Caracteristici:
    - Hybrid memory + disk storage
    - Strategii adaptive (LRU, TTL, size-based)
    - Auto-cleanup cÃ¢nd memoria e scÄƒzutÄƒ
    - Prioritizare bazatÄƒ pe frecvenÈ›Äƒ È™i mÄƒrime
    - Integration cu memory manager
    """
    
    def __init__(self, 
                 memory_cache_size: int = 500,
                 disk_cache_size_mb: int = 50,
                 default_ttl: Optional[float] = 3600,  # 1 orÄƒ
                 strategy: CacheStrategy = CacheStrategy.SMART):
        
        self.strategy = strategy
        self.default_ttl = default_ttl
        
        # Initialize caches
        self.memory_cache = LRUCache[T](max_size=memory_cache_size, ttl=default_ttl)
        self.disk_cache = DiskCache(max_size_mb=disk_cache_size_mb)
        
        # Statistics
        self.stats = {
            'total_requests': 0,
            'memory_hits': 0,
            'disk_hits': 0,
            'misses': 0,
            'evictions': 0
        }
        
        # Background cleanup
        self.cleanup_thread = None
        self.should_stop = False
        self.cleanup_interval = 300  # 5 minute
        
        # Configuration
        if config:
            cache_config = config.get('cache', {})
            self.default_ttl = cache_config.get('default_ttl', default_ttl)
            self.cleanup_interval = cache_config.get('cleanup_interval', 300)
            
        self._start_cleanup_thread()
        
        logger.info(f"ðŸ§  Smart Cache initialized - Strategy: {strategy.value}")
        
    def get(self, key: str) -> Optional[T]:
        """ObÈ›ine o valoare din cache (memory -> disk)"""
        self.stats['total_requests'] += 1
        
        # ÃŽncearcÄƒ mai Ã®ntÃ¢i memory cache
        value = self.memory_cache.get(key)
        if value is not None:
            self.stats['memory_hits'] += 1
            return value
            
        # ÃŽncearcÄƒ disk cache
        value = self.disk_cache.get(key)
        if value is not None:
            self.stats['disk_hits'] += 1
            
            # PromoveazÄƒ Ã®n memory cache dacÄƒ e folosit des
            self._promote_to_memory(key, value)
            return value
            
        # Miss complet
        self.stats['misses'] += 1
        return None
        
    def put(self, key: str, 
            value: T, 
            ttl: Optional[float] = None,
            priority: str = "normal",
            metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Pune o valoare Ã®n cache cu strategie inteligentÄƒ
        
        Args:
            key: Cheia cache-ului
            value: Valoarea de cached
            ttl: Time to live (opcional)
            priority: Prioritatea ("high", "normal", "low") 
            metadata: Metadate suplimentare
        """
        
        effective_ttl = ttl or self.default_ttl
        cache_metadata = metadata or {}
        cache_metadata['priority'] = priority
        cache_metadata['created_by'] = 'smart_cache'
        
        # VerificÄƒ dimensiunea valorii
        try:
            value_size = len(str(value).encode('utf-8'))
        except:
            value_size = 1024
            
        # Strategie de plasare
        success = False
        
        if self.strategy == CacheStrategy.SMART:
            success = self._smart_put(key, value, effective_ttl, value_size, cache_metadata)
        elif self.strategy == CacheStrategy.LRU:
            # Doar memory cache cu LRU
            success = self.memory_cache.put(key, value, effective_ttl, cache_metadata)
        else:
            # Pentru alte strategii, foloseÈ™te memory cache
            success = self.memory_cache.put(key, value, effective_ttl, cache_metadata)
            
        # ÃŽnregistreazÄƒ allocation Ã®n memory manager dacÄƒ e Ã®n memorie
        if success and memory_manager:
            memory_manager.track_allocation(
                f"cache_{key}",
                value_size / (1024 * 1024),  # MB
                MemoryPriority.LOW,
                lambda: self.remove(key)
            )
            
        return success
        
    def _smart_put(self, key: str, value: T, ttl: float, value_size: int, metadata: Dict[str, Any]) -> bool:
        """Strategie inteligentÄƒ de plasare Ã®n cache"""
        
        # Pentru valori mici È™i prioritate Ã®naltÄƒ -> memory
        if value_size < 10240 and metadata.get('priority') == 'high':  # < 10KB
            return self.memory_cache.put(key, value, ttl, metadata)
            
        # Pentru valori mari -> disk
        if value_size > 1024 * 1024:  # > 1MB
            return self.disk_cache.put(key, value, ttl, metadata)
            
        # Pentru prioritate normalÄƒ, Ã®ncearcÄƒ memory, apoi disk
        if self.memory_cache.put(key, value, ttl, metadata):
            return True
        else:
            return self.disk_cache.put(key, value, ttl, metadata)
            
    def _promote_to_memory(self, key: str, value: T):
        """PromoveazÄƒ o valoare din disk Ã®n memory cache"""
        try:
            # VerificÄƒ dacÄƒ avem spaÈ›iu È™i dacÄƒ meritÄƒ
            if len(self.memory_cache.cache) < self.memory_cache.max_size * 0.8:
                self.memory_cache.put(key, value, self.default_ttl)
        except Exception as e:
            logger.debug(f"Could not promote {key} to memory: {e}")
            
    def remove(self, key: str) -> bool:
        """EliminÄƒ o intrare din ambele cache-uri"""
        memory_removed = self.memory_cache.remove(key)
        disk_removed = self.disk_cache.remove(key)
        
        # ElibereazÄƒ allocation din memory manager
        if memory_manager:
            memory_manager.release_allocation(f"cache_{key}")
            
        return memory_removed or disk_removed
        
    def clear(self):
        """CurÄƒÈ›Äƒ ambele cache-uri"""
        self.memory_cache.clear()
        self.disk_cache.clear()
        
        # Reset statistics
        self.stats = {k: 0 for k in self.stats}
        
    def _start_cleanup_thread(self):
        """PorneÈ™te thread-ul de cleanup"""
        if self.cleanup_thread is None or not self.cleanup_thread.is_alive():
            self.cleanup_thread = threading.Thread(
                target=self._cleanup_loop,
                daemon=True,
                name="CacheCleanup"
            )
            self.cleanup_thread.start()
            
    def _cleanup_loop(self):
        """Loop de cleanup periodic"""
        while not self.should_stop:
            try:
                # Cleanup expired entries
                memory_cleaned = self.memory_cache.cleanup_expired()
                disk_cleaned = self.disk_cache.cleanup_expired()
                
                if memory_cleaned > 0 or disk_cleaned > 0:
                    logger.info(f"ðŸ§¹ Cache cleanup: {memory_cleaned} memory, {disk_cleaned} disk entries")
                    
                # VerificÄƒ presiunea memoriei
                if memory_manager:
                    memory_status = asyncio.run(memory_manager.get_memory_status())
                    if memory_status.get('usage_percent', 0) > 85:
                        # Cleanup agresiv cÃ¢nd memoria e scÄƒzutÄƒ
                        self._aggressive_cleanup()
                        
                time.sleep(self.cleanup_interval)
                
            except Exception as e:
                logger.error(f"âŒ Cache cleanup error: {e}")
                time.sleep(60)
                
    def _aggressive_cleanup(self):
        """Cleanup agresiv cÃ¢nd memoria e scÄƒzutÄƒ"""
        # Reduce memory cache size temporar
        original_size = self.memory_cache.max_size
        self.memory_cache.max_size = max(50, original_size // 2)
        
        # EliminÄƒ intrÄƒrile mai puÈ›in folosite
        with self.memory_cache.lock:
            # SorteazÄƒ dupÄƒ access_count È™i eliminÄƒ jumÄƒtate
            entries = list(self.memory_cache.cache.items())
            entries.sort(key=lambda x: x[1].access_count)
            
            to_remove = entries[:len(entries)//2]
            for key, _ in to_remove:
                self.memory_cache.cache.pop(key, None)
                
        logger.warning(f"âš¡ Aggressive cache cleanup: reduced from {original_size} to {self.memory_cache.max_size}")
        
        # RestaureazÄƒ dimensiunea dupÄƒ 5 minute
        def restore_size():
            time.sleep(300)
            self.memory_cache.max_size = original_size
            
        threading.Thread(target=restore_size, daemon=True).start()
        
    async def get_stats(self) -> Dict[str, Any]:
        """ObÈ›ine statistici complete ale cache-ului"""
        
        memory_stats = self.memory_cache.get_stats()
        disk_stats = self.disk_cache.get_stats()
        
        total_requests = self.stats['total_requests']
        overall_hit_rate = 0
        
        if total_requests > 0:
            total_hits = self.stats['memory_hits'] + self.stats['disk_hits']
            overall_hit_rate = (total_hits / total_requests) * 100
            
        return {
            "strategy": self.strategy.value,
            "overall": {
                "hit_rate_percent": round(overall_hit_rate, 2),
                "total_requests": total_requests,
                "memory_hits": self.stats['memory_hits'],
                "disk_hits": self.stats['disk_hits'],
                "misses": self.stats['misses'],
                "memory_hit_rate": round((self.stats['memory_hits'] / total_requests * 100) if total_requests > 0 else 0, 2),
                "disk_hit_rate": round((self.stats['disk_hits'] / total_requests * 100) if total_requests > 0 else 0, 2)
            },
            "memory_cache": memory_stats,
            "disk_cache": disk_stats,
            "health": {
                "cleanup_thread_alive": self.cleanup_thread.is_alive() if self.cleanup_thread else False,
                "total_entries": memory_stats.get('entries', 0) + disk_stats.get('entries', 0)
            }
        }
        
    def stop(self):
        """OpreÈ™te cache-ul È™i cleanup thread"""
        self.should_stop = True
        if self.cleanup_thread and self.cleanup_thread.is_alive():
            self.cleanup_thread.join(timeout=5)
            
        logger.info("ðŸ§  Smart Cache stopped")

# Helper functions pentru cache keys
def generate_cache_key(prefix: str, *args, **kwargs) -> str:
    """GenereazÄƒ o cheie de cache consistentÄƒ"""
    
    # CombinÄƒ argumentele Ã®ntr-un string
    key_parts = [prefix]
    key_parts.extend(str(arg) for arg in args)
    
    # AdaugÄƒ kwargs sortate
    for k, v in sorted(kwargs.items()):
        key_parts.append(f"{k}={v}")
        
    key_string = "|".join(key_parts)
    
    # Hash pentru lungime consistentÄƒ
    return hashlib.sha256(key_string.encode('utf-8')).hexdigest()[:32]

# Cache decorator
def cached(ttl: Optional[float] = None, 
          key_prefix: str = "default",
          priority: str = "normal"):
    """
    Decorator pentru cache automat
    
    Usage:
        @cached(ttl=3600, key_prefix="video_metadata")
        def get_video_info(url):
            # expensive operation
            return video_info
    """
    def decorator(func):
        if asyncio.iscoroutinefunction(func):
            async def async_wrapper(*args, **kwargs):
                # GenereazÄƒ cheia cache
                cache_key = generate_cache_key(f"{key_prefix}_{func.__name__}", *args, **kwargs)
                
                # ÃŽncearcÄƒ sÄƒ obÈ›ii din cache
                cached_result = cache.get(cache_key)
                if cached_result is not None:
                    return cached_result
                    
                # ExecutÄƒ funcÈ›ia
                result = await func(*args, **kwargs)
                
                # SalveazÄƒ Ã®n cache
                if result is not None:
                    cache.put(cache_key, result, ttl=ttl, priority=priority)
                    
                return result
            return async_wrapper
        else:
            def sync_wrapper(*args, **kwargs):
                # GenereazÄƒ cheia cache
                cache_key = generate_cache_key(f"{key_prefix}_{func.__name__}", *args, **kwargs)
                
                # ÃŽncearcÄƒ sÄƒ obÈ›ii din cache
                cached_result = cache.get(cache_key)
                if cached_result is not None:
                    return cached_result
                    
                # ExecutÄƒ funcÈ›ia
                result = func(*args, **kwargs)
                
                # SalveazÄƒ Ã®n cache
                if result is not None:
                    cache.put(cache_key, result, ttl=ttl, priority=priority)
                    
                return result
            return sync_wrapper
    return decorator

# Singleton instance
cache = SmartCache[Any](
    memory_cache_size=500,
    disk_cache_size_mb=50,
    default_ttl=3600,  # 1 orÄƒ
    strategy=CacheStrategy.SMART
)
