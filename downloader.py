import yt_dlp
import os
import tempfile
import time
import glob
import re
import unicodedata
import random
import json
import logging
from datetime import datetime, timedelta

# Configurare logging centralizat
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ConfiguraÈ›ii pentru clienÈ›ii YouTube recomandaÈ›i de yt-dlp (2024)
# Bazat pe https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies
YOUTUBE_CLIENT_CONFIGS = {
    'mweb': {
        'player_client': 'mweb',
        'description': 'Mobile web client - recomandat pentru evitarea PO Token',
        'requires_po_token': False,  # Nu necesitÄƒ PO Token conform documentaÈ›iei
        'supports_hls': True,
        'priority': 1  # Prioritate maximÄƒ
    },
    'tv_embedded': {
        'player_client': 'tv_embedded', 
        'description': 'TV embedded client - nu necesitÄƒ PO Token',
        'requires_po_token': False,
        'supports_hls': True,
        'priority': 2
    },
    'web_safari': {
        'player_client': 'web_safari',
        'description': 'Safari web client - oferÄƒ HLS fÄƒrÄƒ PO Token',
        'requires_po_token': False,
        'supports_hls': True,
        'priority': 3
    },
    'android_vr': {
        'player_client': 'android_vr',
        'description': 'Android VR client - nu necesitÄƒ PO Token',
        'requires_po_token': False,
        'supports_hls': False,
        'priority': 4
    },
    # ClienÈ›i suplimentari pentru cazuri extreme
    'mediaconnect': {
        'player_client': 'mediaconnect',
        'description': 'Media Connect client - pentru cazuri speciale',
        'requires_po_token': False,
        'supports_hls': False,
        'priority': 5
    }
}

# Lista de User Agents reali pentru a evita detecÈ›ia
REAL_USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/120.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
]

# Lista de Accept-Language headers reali
ACCEPT_LANGUAGES = [
    'en-US,en;q=0.9',
    'en-GB,en;q=0.9',
    'en-US,en;q=0.8,es;q=0.6',
    'en-US,en;q=0.9,fr;q=0.8',
    'en-US,en;q=0.9,de;q=0.8',
    'en-US,en;q=0.9,it;q=0.8',
    'en-US,en;q=0.9,pt;q=0.8',
]

def get_random_headers():
    """GenereazÄƒ headers HTTP reali pentru a evita detecÈ›ia"""
    user_agent = random.choice(REAL_USER_AGENTS)
    accept_language = random.choice(ACCEPT_LANGUAGES)
    
    # GenereazÄƒ un viewport realist bazat pe user agent
    if 'Mobile' in user_agent or 'Android' in user_agent:
        viewport = random.choice(['375x667', '414x896', '360x640', '412x915'])
    else:
        viewport = random.choice(['1920x1080', '1366x768', '1536x864', '1440x900', '1280x720'])
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': accept_language,
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
    }
    
    # AdaugÄƒ headers specifice pentru Chrome
    if 'Chrome' in user_agent and 'Edg' not in user_agent:
        headers.update({
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0' if 'Mobile' not in user_agent else '?1',
            'sec-ch-ua-platform': '"Windows"' if 'Windows' in user_agent else ('"macOS"' if 'Mac' in user_agent else '"Linux"'),
        })
    
    return headers

def get_youtube_cookies():
    """GenereazÄƒ cookies simulate pentru YouTube (fÄƒrÄƒ a fi trimise ca header pentru securitate)
    Conform avertismentului yt-dlp, cookies nu trebuie trimise ca header HTTP
    """
    # Nu mai returnÄƒm cookies ca string Ã®n header pentru a evita avertismentul de securitate
    # Ãn schimb, folosim configuraÈ›ii extractor specifice
    return None

def get_youtube_extractor_args(client_type='mweb'):
    """ConfigureazÄƒ argumentele extractor pentru YouTube conform documentaÈ›iei oficiale"""
    client_config = YOUTUBE_CLIENT_CONFIGS.get(client_type, YOUTUBE_CLIENT_CONFIGS['mweb'])
    
    # ConfiguraÈ›ii de bazÄƒ pentru extractor
    extractor_args = {
        'youtube': {
            'player_client': [client_config['player_client']],
            # ConfiguraÈ›ii pentru evitarea PO Token
            'player_skip': ['webpage', 'configs'] if not client_config.get('requires_po_token') else [],
            # ConfiguraÈ›ii pentru HLS
            'skip': [] if client_config.get('supports_hls') else ['hls'],
            # ConfiguraÈ›ii suplimentare pentru anti-detecÈ›ie
            'innertube_host': 'www.youtube.com',
            'innertube_key': None,  # LasÄƒ yt-dlp sÄƒ detecteze automat
            'comment_sort': 'top',
            'max_comments': [0],  # Nu extrage comentarii
        }
    }
    
    # ConfiguraÈ›ii specifice pentru client mweb (recomandat)
    if client_type == 'mweb':
        extractor_args['youtube'].update({
            'player_client': ['mweb'],
            'player_skip': ['webpage'],  # Skip webpage pentru mweb
            'innertube_host': 'm.youtube.com',  # Host mobil
        })
    
    # ConfiguraÈ›ii pentru tv_embedded
    elif client_type == 'tv_embedded':
        extractor_args['youtube'].update({
            'player_client': ['tv_embedded'],
            'player_skip': ['webpage', 'configs'],
        })
    
    # ConfiguraÈ›ii pentru web_safari
    elif client_type == 'web_safari':
        extractor_args['youtube'].update({
            'player_client': ['web_safari'],
            'player_skip': ['webpage'],
        })
    
    return extractor_args

def create_youtube_session_advanced(client_type='mweb'):
    """CreeazÄƒ o sesiune YouTube avansatÄƒ cu configuraÈ›ii anti-detecÈ›ie È™i client optim"""
    headers = get_random_headers()
    client_config = YOUTUBE_CLIENT_CONFIGS.get(client_type, YOUTUBE_CLIENT_CONFIGS['mweb'])
    extractor_args = get_youtube_extractor_args(client_type)
    
    # ConfiguraÈ›ii avansate pentru a evita detecÈ›ia
    session_config = {
        'http_headers': headers,
        'cookiefile': None,  # Nu salvÄƒm cookies pe disk pentru securitate
        'nocheckcertificate': False,
        'prefer_insecure': False,
        'cachedir': False,  # DezactiveazÄƒ cache pentru a evita detecÈ›ia
        'no_warnings': True,
        'extract_flat': False,
        'ignoreerrors': False,
        'geo_bypass': True,
        'geo_bypass_country': random.choice(['US', 'GB', 'CA', 'AU']),
        'age_limit': None,
        'sleep_interval': random.uniform(2, 5),  # PauzÄƒ randomizatÄƒ
        'max_sleep_interval': random.uniform(10, 20),
        'sleep_interval_subtitles': random.uniform(1, 3),
        'socket_timeout': random.randint(120, 180),
        'retries': 2,
        'extractor_retries': 3,
        'fragment_retries': 5,
        'retry_sleep_functions': {
            'http': lambda n: min(3 ** n + random.uniform(1, 3), 60),
            'fragment': lambda n: min(3 ** n + random.uniform(1, 3), 60)
        },
        # ConfiguraÈ›ii extractor optimizate
        'extractor_args': extractor_args,
        # SimuleazÄƒ comportament de browser real
        'extract_comments': False,
        'writesubtitles': False,
        'writeautomaticsub': False,
        'embed_subs': False,
        'writeinfojson': False,
        'writethumbnail': False,
        'writedescription': False,
        'writeannotations': False,
        # ConfiguraÈ›ii suplimentare pentru evitarea detecÈ›iei
        'no_color': True,
        'no_check_certificate': False,
        'prefer_free_formats': True,
        'youtube_include_dash_manifest': False,  # EvitÄƒ DASH pentru simplitate
    }
    
    # Nu mai adÄƒugÄƒm cookies Ã®n header pentru a evita avertismentele de securitate
    # Cookies sunt gestionate prin configuraÈ›ii extractor specifice
    
    return session_config, client_config

def create_youtube_session():
    """CreeazÄƒ o sesiune YouTube cu configuraÈ›ii anti-detecÈ›ie"""
    headers = get_random_headers()
    
    # ConfiguraÈ›ii avansate pentru a evita detecÈ›ia
    session_config = {
        'http_headers': headers,
        'cookiefile': None,  # Nu salvÄƒm cookies pe disk
        'nocheckcertificate': False,
        'prefer_insecure': False,
        'cachedir': False,
        'no_warnings': True,
        'extract_flat': False,
        'ignoreerrors': False,
        'geo_bypass': True,
        'geo_bypass_country': 'US',
        'age_limit': None,
        'sleep_interval': random.uniform(1.5, 3.5),  # PauzÄƒ randomizatÄƒ
        'max_sleep_interval': random.uniform(8, 15),
        'sleep_interval_subtitles': random.uniform(1, 3),
        'socket_timeout': random.randint(90, 150),
        'retries': 2,
        'extractor_retries': 3,
        'fragment_retries': 5,
        'retry_sleep_functions': {
            'http': lambda n: min(2 ** n + random.uniform(0.5, 2), 30),
            'fragment': lambda n: min(2 ** n + random.uniform(0.5, 2), 30)
        },
        # SimuleazÄƒ comportament de browser real
        'extract_comments': False,
        'writesubtitles': False,
        'writeautomaticsub': False,
        'embed_subs': False,
        'writeinfojson': False,
        'writethumbnail': False,
        'writedescription': False,
        'writeannotations': False,
    }
    
    # Nu mai adÄƒugÄƒm cookies Ã®n header pentru a evita avertismentele de securitate
    # Cookies sunt gestionate prin configuraÈ›ii extractor specifice
    
    return session_config

def is_youtube_bot_detection_error(error_msg):
    """DetecteazÄƒ dacÄƒ eroarea este cauzatÄƒ de sistemul anti-bot YouTube sau necesitÄƒ PO Token"""
    bot_detection_keywords = [
        # Erori de rate limiting
        'HTTP Error 429',
        'Too Many Requests',
        'rate limit',
        'quota exceeded',
        
        # Erori de detecÈ›ie bot
        'bot',
        'automated',
        'suspicious',
        'blocked',
        'forbidden',
        'access denied',
        'captcha',
        'verification',
        'unusual traffic',
        'service unavailable',
        'temporarily unavailable',
        'sign in to confirm',
        'Sign in required',
        'not a bot',
        'protect our community',
        
        # Erori specifice PO Token (conform documentaÈ›iei yt-dlp)
        'po_token',
        'proof of origin',
        'player response',
        'playability status',
        'login required',
        'members only',
        'private video',
        'age-restricted',
        'region blocked',
        'video unavailable',
        
        # Erori de client nesuportat
        'client not supported',
        'invalid client',
        'client error',
        'player error',
        'extraction failed',
        
        # Erori de cookies
        'cookie',
        'authentication',
        'session',
        'csrf',
        'token expired',
        
        # Erori DNS È™i de conectivitate
        'failed to resolve',
        'name or service not known',
        'unable to download api page',
        'failed to extract any player response'
    ]
    
    error_lower = str(error_msg).lower()
    return any(keyword.lower() in error_lower for keyword in bot_detection_keywords)

def is_po_token_required_error(error_msg):
    """DetecteazÄƒ dacÄƒ eroarea indicÄƒ necesitatea unui PO Token"""
    po_token_keywords = [
        'po_token',
        'proof of origin',
        'player response',
        'playability status',
        'sign in to confirm',
        'login required',
        'members only'
    ]
    
    error_lower = str(error_msg).lower()
    return any(keyword.lower() in error_lower for keyword in po_token_keywords)

def get_youtube_retry_strategy(attempt_number):
    """ReturneazÄƒ strategia de retry bazatÄƒ pe numÄƒrul Ã®ncercÄƒrii"""
    strategies = [
        {  # Prima Ã®ncercare - configuraÈ›ii standard
            'format': 'best[height<=720]/best',
            'sleep_multiplier': 1.0,
            'geo_country': 'US'
        },
        {  # A doua Ã®ncercare - calitate mai micÄƒ
            'format': 'best[height<=480]/best',
            'sleep_multiplier': 1.5,
            'geo_country': 'GB'
        },
        {  # A treia Ã®ncercare - calitate minimÄƒ
            'format': 'worst[height<=360]/worst',
            'sleep_multiplier': 2.0,
            'geo_country': 'CA'
        }
    ]
    
    if attempt_number < len(strategies):
        return strategies[attempt_number]
    else:
        # Pentru Ã®ncercÄƒri suplimentare, foloseÈ™te ultima strategie cu delay crescut
        last_strategy = strategies[-1].copy()
        last_strategy['sleep_multiplier'] = 3.0 + (attempt_number - len(strategies))
        last_strategy['geo_country'] = random.choice(['AU', 'NZ', 'IE', 'NL'])
        return last_strategy

def get_youtube_retry_strategy_advanced(attempt_number):
    """ReturneazÄƒ strategia de retry avansatÄƒ cu clienÈ›i optimi conform documentaÈ›iei yt-dlp 2024"""
    strategies = [
        {  # Prima Ã®ncercare - client mweb (cel mai recomandat)
            'client': 'mweb',
            'format': 'best[height<=720]/best',
            'sleep_multiplier': 1.0,
            'geo_country': 'US',
            'description': 'Client mweb - prioritate maximÄƒ, nu necesitÄƒ PO Token',
            'priority': 1
        },
        {  # A doua Ã®ncercare - client tv_embedded
            'client': 'tv_embedded', 
            'format': 'best[height<=480]/best',
            'sleep_multiplier': 1.5,
            'geo_country': 'GB',
            'description': 'Client TV embedded - fÄƒrÄƒ PO Token, suportÄƒ HLS',
            'priority': 2
        },
        {  # A treia Ã®ncercare - client web_safari cu HLS
            'client': 'web_safari',
            'format': 'best[height<=360]/best',
            'sleep_multiplier': 2.0,
            'geo_country': 'CA',
            'description': 'Client Safari cu HLS - fÄƒrÄƒ PO Token',
            'priority': 3
        },
        {  # A patra Ã®ncercare - client android_vr
            'client': 'android_vr',
            'format': 'worst[height<=360]/worst',
            'sleep_multiplier': 2.5,
            'geo_country': 'AU',
            'description': 'Client Android VR - fÄƒrÄƒ HLS dar stabil',
            'priority': 4
        },
        {  # A cincea Ã®ncercare - client mediaconnect pentru cazuri extreme
            'client': 'mediaconnect',
            'format': 'worst[height<=240]/worst',
            'sleep_multiplier': 3.0,
            'geo_country': 'NZ',
            'description': 'Client MediaConnect - pentru cazuri speciale',
            'priority': 5
        }
    ]
    
    if attempt_number < len(strategies):
        return strategies[attempt_number]
    else:
        # Pentru Ã®ncercÄƒri suplimentare, foloseÈ™te strategii randomizate
        fallback_strategy = {
            'client': random.choice(['mweb', 'tv_embedded', 'web_safari']),
            'format': 'worst[height<=240]/worst',
            'sleep_multiplier': 3.0 + (attempt_number - len(strategies)) * 0.5,
            'geo_country': random.choice(['NZ', 'IE', 'NL', 'DE', 'FR', 'IT', 'ES']),
            'description': f'Fallback #{attempt_number + 1} - strategie randomizatÄƒ',
            'priority': 6 + attempt_number
        }
        return fallback_strategy

def clean_title(title):
    """
    CurÄƒÈ›Äƒ titlul de emoticoane, caractere Unicode problematice È™i alte caractere speciale
    """
    if not title:
        return ""
    
    # ÃnlocuieÈ™te newlines È™i carriage returns cu spaÈ›ii
    title = title.replace('\n', ' ').replace('\r', ' ')
    
    # EliminÄƒ emoticoanele È™i simbolurile Unicode problematice
    # PÄƒstreazÄƒ doar caracterele alfanumerice, spaÈ›iile È™i punctuaÈ›ia de bazÄƒ
    title = re.sub(r'[^\w\s\-_.,!?()\[\]{}"\':;]+', '', title, flags=re.UNICODE)
    
    # NormalizeazÄƒ caracterele Unicode (converteÈ™te caractere accentuate la forma de bazÄƒ)
    title = unicodedata.normalize('NFKD', title)
    
    # EliminÄƒ caracterele de control È™i caracterele invizibile
    title = ''.join(char for char in title if unicodedata.category(char)[0] != 'C')
    
    # CurÄƒÈ›Äƒ spaÈ›iile multiple È™i trim
    title = re.sub(r'\s+', ' ', title).strip()
    
    # LimiteazÄƒ lungimea titlului pentru a evita probleme
    if len(title) > 200:
        title = title[:200].strip()
        if not title.endswith('...'):
            title += '...'
    
    return title if title else "Video"

def try_youtube_fallback(url, output_path, title):
    """
    ÃncearcÄƒ descÄƒrcarea YouTube cu opÈ›iuni ultra-conservative È™i anti-detecÈ›ie pentru a evita rate limiting
    """
    # CreeazÄƒ o sesiune cu configuraÈ›ii anti-detecÈ›ie pentru fallback
    session_config = create_youtube_session()
    
    fallback_opts = {
        'outtmpl': output_path,
        'format': 'worst[height<=360]/worst[height<=240]/worst',  # Calitate foarte micÄƒ
        'quiet': True,
        'noplaylist': True,
        'extractaudio': False,
        'embed_subs': False,
        'writesubtitles': False,
        'writeautomaticsub': False,
        # FoloseÈ™te headers anti-detecÈ›ie din sesiune
        'http_headers': session_config['http_headers'],
        'extractor_retries': 2,  # ÃncercÄƒri moderate
        'fragment_retries': 3,
        'retry_sleep_functions': {
            'http': lambda n: min(5 ** n + random.uniform(1, 3), 120),  # Delay randomizat
            'fragment': lambda n: min(5 ** n + random.uniform(1, 3), 120)
        },
        'socket_timeout': random.randint(90, 150),  # Timeout randomizat
        'retries': 1,  # O reÃ®ncercare
        'sleep_interval': random.uniform(8, 12),  # PauzÄƒ randomizatÄƒ Ã®ntre cereri
        'max_sleep_interval': random.uniform(25, 35),
        'sleep_interval_subtitles': random.uniform(5, 8),
        'nocheckcertificate': False,
        'prefer_insecure': False,
        'cachedir': False,
        'no_warnings': True,
        'extract_flat': False,
        'ignoreerrors': False,
        'geo_bypass': True,
        'geo_bypass_country': random.choice(['US', 'GB', 'CA', 'AU']),  # ÈšarÄƒ randomizatÄƒ
        # ConfiguraÈ›ii anti-detecÈ›ie suplimentare
        'age_limit': None,
        'writeinfojson': False,
        'writethumbnail': False,
        'writedescription': False,
        'writeannotations': False,
        'extract_comments': False,
    }
    
    try:
        with yt_dlp.YoutubeDL(fallback_opts) as ydl:
            # AdaugÄƒ un delay randomizat Ã®nainte de Ã®ncercare pentru a simula comportament uman
            time.sleep(random.uniform(10, 20))
            ydl.download([url])
            
            # GÄƒseÈ™te fiÈ™ierul descÄƒrcat
            temp_dir = os.path.dirname(output_path)
            downloaded_files = glob.glob(os.path.join(temp_dir, "*"))
            downloaded_files = [f for f in downloaded_files if os.path.isfile(f)]
            
            if downloaded_files:
                return {
                    'success': True,
                    'file_path': downloaded_files[0],
                    'title': title,
                    'description': '',
                    'uploader': '',
                    'duration': 0,
                    'file_size': os.path.getsize(downloaded_files[0])
                }
    except Exception:
        pass
    
    return {
        'success': False,
        'error': 'âŒ YouTube: Nu s-a putut descÄƒrca nici cu opÈ›iunile alternative. ÃncearcÄƒ din nou mai tÃ¢rziu.',
        'title': title
    }

def try_facebook_fallback(url, output_path, title):
    """
    ÃncearcÄƒ descÄƒrcarea Facebook cu opÈ›iuni alternative
    """
    # ConfiguraÈ›ie alternativÄƒ pentru Facebook
    fallback_opts = {
        'outtmpl': output_path,
        'format': 'worst[height<=480]/worst',  # Calitate mai micÄƒ pentru compatibilitate
        'quiet': True,
        'noplaylist': True,
        'extractaudio': False,
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
        },
        'extractor_retries': 2,
        'fragment_retries': 2,
        'socket_timeout': 15,
        'retries': 2,
        'ignoreerrors': True,
        # OpÈ›iuni specifice pentru probleme de parsare
        'extract_flat': True,
        'skip_download': False,
    }
    
    try:
        with yt_dlp.YoutubeDL(fallback_opts) as ydl:
            # ÃncearcÄƒ sÄƒ descarce cu opÈ›iuni alternative
            ydl.download([url])
            
            # GÄƒseÈ™te fiÈ™ierul descÄƒrcat
            temp_dir = os.path.dirname(output_path)
            downloaded_files = glob.glob(os.path.join(temp_dir, "*"))
            downloaded_files = [f for f in downloaded_files if os.path.isfile(f)]
            
            if downloaded_files:
                downloaded_file = downloaded_files[0]
                file_size = os.path.getsize(downloaded_file)
                
                return {
                    'success': True,
                    'file_path': downloaded_file,
                    'title': title or "Video Facebook",
                    'description': "DescÄƒrcat cu opÈ›iuni alternative",
                    'uploader': "Facebook",
                    'duration': 0,
                    'file_size': file_size
                }
            else:
                return {
                    'success': False,
                    'error': 'âŒ Facebook: Nu s-a putut descÄƒrca videoul cu opÈ›iunile alternative.',
                    'title': title or 'N/A'
                }
                
    except Exception as e:
        return {
            'success': False,
            'error': f'âŒ Facebook: Eroare la Ã®ncercarea alternativÄƒ: {str(e)}',
            'title': title or 'N/A'
        }

def validate_url(url):
    """ValideazÄƒ URL-ul pentru a preveni erorile DNS"""
    if not url or len(url.strip()) < 10:
        return False, "URL invalid sau prea scurt"
    
    url = url.strip()
    
    # VerificÄƒ dacÄƒ URL-ul conÈ›ine domenii suportate
    supported_domains = [
        'youtube.com', 'youtu.be', 'tiktok.com', 'instagram.com', 
        'facebook.com', 'fb.watch', 'twitter.com', 'x.com'
    ]
    
    if not any(domain in url.lower() for domain in supported_domains):
        return False, "Domeniu nesuportat"
    
    # VerificÄƒ dacÄƒ URL-ul nu este corupt (ex: doar "w")
    if len(url) < 15 or not url.startswith(('http://', 'https://')):
        return False, "URL corupt sau incomplet"
    
    return True, "URL valid"

def download_video(url, output_path=None):
    """
    DescarcÄƒ un video de pe YouTube, TikTok, Instagram sau Facebook
    ReturneazÄƒ un dicÈ›ionar cu rezultatul
    """
    # ValideazÄƒ URL-ul Ã®nainte de procesare
    is_valid, validation_msg = validate_url(url)
    if not is_valid:
        return {
            'success': False,
            'error': f'âŒ URL invalid: {validation_msg}',
            'title': 'N/A'
        }
    
    # CreeazÄƒ directorul temporar ÃNTOTDEAUNA
    temp_dir = tempfile.mkdtemp()
    
    if output_path is None:
        output_path = os.path.join(temp_dir, "%(title)s.%(ext)s")
    
    # ConfiguraÈ›ie specificÄƒ pentru YouTube cu mÄƒsuri anti-detecÈ›ie avansate (2024)
    if 'youtube.com' in url.lower() or 'youtu.be' in url.lower():
        print("Detectat link YouTube - folosesc clienÈ›i optimi conform documentaÈ›iei yt-dlp")
        
        # ÃncearcÄƒ cu clienÈ›i optimi Ã®n ordine de prioritate
        max_attempts = 5  # Include È™i clientul mediaconnect
        downloaded_files = []
        
        for attempt in range(max_attempts):
            try:
                strategy = get_youtube_retry_strategy_advanced(attempt)
                session_config, client_config = create_youtube_session_advanced(strategy['client'])
                
                print(f"Ãncercare YouTube #{attempt + 1}/{max_attempts}: {strategy['description']}")
                print(f"Client: {strategy['client']}, Prioritate: {strategy.get('priority', 'N/A')}")
                
                ydl_opts = {
                    'format': strategy['format'],
                    'outtmpl': output_path,
                    'quiet': True,
                    'no_warnings': True,
                    'extractaudio': False,
                    'audioformat': 'mp3',
                    'embed_subs': False,
                    'writesubtitles': False,
                    'writeautomaticsub': False,
                    'ignoreerrors': True,
                    'noplaylist': True,
                    'retries': session_config.get('retries', 2),
                    'extractor_retries': session_config.get('extractor_retries', 3),
                    'fragment_retries': session_config.get('fragment_retries', 5),
                    'socket_timeout': session_config.get('socket_timeout', 120),
                    'http_headers': session_config['http_headers'],
                    'sleep_interval': session_config.get('sleep_interval', 2) * strategy['sleep_multiplier'],
                    'max_sleep_interval': session_config.get('max_sleep_interval', 10) * strategy['sleep_multiplier'],
                    'sleep_interval_subtitles': session_config.get('sleep_interval_subtitles', 2) * strategy['sleep_multiplier'],
                    'retry_sleep_functions': session_config.get('retry_sleep_functions', {}),
                    # ConfiguraÈ›ii suplimentare anti-detecÈ›ie
                    'geo_bypass': session_config.get('geo_bypass', True),
                    'geo_bypass_country': strategy['geo_country'],
                    'cachedir': False,
                    'nocheckcertificate': False,
                    'prefer_insecure': False,
                    'age_limit': None,
                    # EvitÄƒ salvarea de metadate care pot fi detectate
                    'writeinfojson': False,
                    'writethumbnail': False,
                    'writedescription': False,
                    'writeannotations': False,
                    'extract_comments': False,
                    # ConfiguraÈ›ii client specifice optimizate
                    'extractor_args': session_config.get('extractor_args', {}),
                    # ConfiguraÈ›ii suplimentare pentru evitarea detecÈ›iei
                    'no_color': True,
                    'prefer_free_formats': True,
                    'youtube_include_dash_manifest': False
                }
                
                # PauzÄƒ adaptivÄƒ Ã®nainte de Ã®ncercare
                delay = random.uniform(3, 8) * strategy['sleep_multiplier']
                print(f"AÈ™tept {delay:.1f} secunde Ã®nainte de Ã®ncercare...")
                time.sleep(delay)
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([url])
                    
                # VerificÄƒ dacÄƒ descÄƒrcarea a reuÈ™it
                downloaded_files = glob.glob(os.path.join(temp_dir, "*"))
                downloaded_files = [f for f in downloaded_files if os.path.isfile(f)]
                
                if downloaded_files:
                    print(f"âœ… DescÄƒrcare YouTube reuÈ™itÄƒ cu {strategy['description']}")
                    print(f"Client folosit: {strategy['client']} (prioritate {strategy.get('priority', 'N/A')})")
                    break
                    
            except Exception as client_error:
                error_msg = str(client_error)
                print(f"âŒ Client {strategy['client']} eÈ™uat: {error_msg}")
                
                # Logging centralizat pentru monitorizare
                logger.error(f"YouTube client {strategy['client']} failed: {error_msg}", extra={
                    'client': strategy['client'],
                    'priority': strategy.get('priority', 'N/A'),
                    'attempt': attempt + 1,
                    'url': url[:50] + '...' if len(url) > 50 else url
                })
                
                # VerificÄƒ dacÄƒ este o eroare care necesitÄƒ PO Token
                if is_po_token_required_error(error_msg):
                    print(f"âš ï¸  DetectatÄƒ eroare PO Token pentru client {strategy['client']}")
                    logger.warning(f"PO Token error detected for client {strategy['client']}")
                
                # VerificÄƒ dacÄƒ este o eroare de detecÈ›ie bot
                if is_youtube_bot_detection_error(error_msg):
                    print(f"ğŸ¤– DetectatÄƒ eroare anti-bot pentru client {strategy['client']}")
                    logger.warning(f"Anti-bot error detected for client {strategy['client']}")
                    # AdaugÄƒ delay suplimentar pentru urmÄƒtoarea Ã®ncercare
                    extra_delay = random.uniform(5, 15)
                    print(f"Adaug delay suplimentar de {extra_delay:.1f} secunde...")
                    time.sleep(extra_delay)
                
                # DacÄƒ este ultima Ã®ncercare cu clienÈ›i, Ã®ncearcÄƒ fallback final
                if attempt == max_attempts - 1:
                    print("ğŸ”„ ToÈ›i clienÈ›ii au eÈ™uat, Ã®ncerc fallback final cu android_vr...")
                    fallback_result = try_youtube_fallback(url, output_path, "fallback_video")
                    if fallback_result:
                        downloaded_files = [fallback_result]
                        print("âœ… Fallback final reuÈ™it!")
                        break
                    else:
                        print("âŒ Fallback final eÈ™uat")
                continue
        
        # DacÄƒ nu s-a descÄƒrcat nimic dupÄƒ toate Ã®ncercÄƒrile
        if not downloaded_files:
            raise Exception("Toate strategiile YouTube au eÈ™uat. Posibil link invalid sau restricÈ›ii severe.")
    else:
        # ConfiguraÈ›ie pentru alte platforme
        ydl_opts = {
            'outtmpl': output_path,
            'format': 'best[height<=720]/best',
            'quiet': True,
            'noplaylist': True,
            'extractaudio': False,
            'audioformat': 'mp3',
            'embed_subs': False,
            'writesubtitles': False,
            'writeautomaticsub': False,
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            },
            'extractor_retries': 5,
            'fragment_retries': 5,
            'retry_sleep_functions': {'http': lambda n: min(4 ** n, 60)},
            'ignoreerrors': False,
            'extract_flat': False,
            'skip_download': False,
            'socket_timeout': 30,
            'retries': 3,
        }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # Extrage informaÈ›ii despre video
            info = ydl.extract_info(url, download=False)
            
            # Extrage titlul È™i alte informaÈ›ii
            title = info.get('title', 'video')
            description = info.get('description', '')
            uploader = info.get('uploader', '')
            duration = info.get('duration', 0)
            
            # ÃmbunÄƒtÄƒÈ›eÈ™te titlul pentru diferite platforme
            if 'instagram.com' in url.lower():
                # Pentru Instagram, Ã®ncearcÄƒ sÄƒ gÄƒseÈ™ti un titlu mai bun
                if description and len(description) > len(title):
                    # Ia primele 100 de caractere din descriere ca titlu
                    title = description[:100].strip()
                    if len(description) > 100:
                        title += '...'
                elif uploader:
                    title = f"Video de la {uploader}"
            
            elif 'tiktok.com' in url.lower():
                # Pentru TikTok, Ã®ncearcÄƒ sÄƒ gÄƒseÈ™ti un titlu mai bun
                if description and len(description) > len(title):
                    # Ia primele 100 de caractere din descriere ca titlu
                    title = description[:100].strip()
                    if len(description) > 100:
                        title += '...'
                elif uploader:
                    title = f"TikTok de la {uploader}"
            
            # CurÄƒÈ›Äƒ titlul de caractere speciale problematice È™i emoticoane
            title = clean_title(title)
            if not title or title == 'video':
                title = f"Video de pe {url.split('/')[2] if '/' in url else 'platformÄƒ necunoscutÄƒ'}"
            
            # VerificÄƒ dacÄƒ videoul nu este prea lung (max 3 ore pentru fiÈ™iere mai mari)
            if duration and duration > 10800:  # 3 ore = 10800 secunde
                return {
                    'success': False,
                    'error': 'Videoul este prea lung (max 3 ore)',
                    'title': title
                }
            
            # DescarcÄƒ videoul
            try:
                ydl.download([url])
            except Exception as download_error:
                error_str = str(download_error).lower()
                # ÃncearcÄƒ cu strategii adaptive pentru YouTube la detectarea erorilor anti-bot
                if ('youtube.com' in url.lower() or 'youtu.be' in url.lower()) and is_youtube_bot_detection_error(str(download_error)):
                    print(f"Eroare anti-bot YouTube detectatÄƒ, Ã®ncerc strategii alternative: {str(download_error)}")
                    
                    # ÃncearcÄƒ mai multe strategii de retry
                    for attempt in range(3):
                        try:
                            print(f"Ãncercare YouTube #{attempt + 1} cu strategie adaptivÄƒ")
                            strategy = get_youtube_retry_strategy(attempt)
                            
                            # CreeazÄƒ o nouÄƒ sesiune pentru fiecare Ã®ncercare
                            session_config = create_youtube_session()
                            
                            # ConfiguraÈ›ii adaptive bazate pe strategie
                            adaptive_opts = {
                                'format': strategy['format'],
                                'outtmpl': output_path,
                                'quiet': True,
                                'no_warnings': True,
                                'extractaudio': False,
                                'embed_subs': False,
                                'writesubtitles': False,
                                'writeautomaticsub': False,
                                'noplaylist': True,
                                'http_headers': session_config['http_headers'],
                                'retries': 1,
                                'extractor_retries': 2,
                                'fragment_retries': 3,
                                'socket_timeout': random.randint(120, 180),
                                'sleep_interval': random.uniform(5, 10) * strategy['sleep_multiplier'],
                                'max_sleep_interval': random.uniform(20, 40) * strategy['sleep_multiplier'],
                                'sleep_interval_subtitles': random.uniform(3, 6) * strategy['sleep_multiplier'],
                                'retry_sleep_functions': {
                                    'http': lambda n: min((7 ** n) * strategy['sleep_multiplier'] + random.uniform(2, 5), 300),
                                    'fragment': lambda n: min((7 ** n) * strategy['sleep_multiplier'] + random.uniform(2, 5), 300)
                                },
                                'geo_bypass': True,
                                'geo_bypass_country': strategy['geo_country'],
                                'cachedir': False,
                                'nocheckcertificate': False,
                                'prefer_insecure': False,
                                'age_limit': None,
                                'extract_flat': False,
                                'ignoreerrors': False,
                                'writeinfojson': False,
                                'writethumbnail': False,
                                'writedescription': False,
                                'writeannotations': False,
                                'extract_comments': False,
                            }
                            
                            # PauzÄƒ adaptivÄƒ Ã®nainte de Ã®ncercare
                            delay = random.uniform(10, 25) * strategy['sleep_multiplier']
                            print(f"AÈ™tept {delay:.1f} secunde Ã®nainte de Ã®ncercare...")
                            time.sleep(delay)
                            
                            with yt_dlp.YoutubeDL(adaptive_opts) as ydl_retry:
                                ydl_retry.download([url])
                                
                            # VerificÄƒ dacÄƒ descÄƒrcarea a reuÈ™it
                            temp_dir = os.path.dirname(output_path)
                            downloaded_files = glob.glob(os.path.join(temp_dir, "*"))
                            downloaded_files = [f for f in downloaded_files if os.path.isfile(f)]
                            
                            if downloaded_files:
                                print(f"DescÄƒrcare YouTube reuÈ™itÄƒ cu strategia #{attempt + 1}")
                                break
                                
                        except Exception as retry_error:
                            print(f"Ãncercarea #{attempt + 1} eÈ™uatÄƒ: {str(retry_error)}")
                            if attempt == 2:  # Ultima Ã®ncercare
                                print("Toate strategiile YouTube au eÈ™uat, Ã®ncerc fallback final")
                                return try_youtube_fallback(url, output_path, title)
                            continue
                # ÃncearcÄƒ cu opÈ›iuni alternative pentru YouTube la alte erori
                elif ('youtube.com' in url.lower() or 'youtu.be' in url.lower()):
                    if ('429' in error_str or 'too many requests' in error_str or 'rate' in error_str or 
                        'unavailable' in error_str or 'private' in error_str or 'blocked' in error_str or
                        'sign in' in error_str or 'login' in error_str or 'bot' in error_str):
                        return try_youtube_fallback(url, output_path, title)
                # ÃncearcÄƒ cu opÈ›iuni alternative pentru Facebook
                elif 'facebook.com' in url.lower() or 'fb.watch' in url.lower():
                    return try_facebook_fallback(url, output_path, title)
                else:
                    raise download_error
            
            # Pentru YouTube, fiÈ™ierele au fost deja gÄƒsite Ã®n bucla de Ã®ncercÄƒri
            # Pentru alte platforme, gÄƒseÈ™te fiÈ™ierul descÄƒrcat Ã®n directorul temporar
            if not ('youtube.com' in url.lower() or 'youtu.be' in url.lower()):
                downloaded_files = glob.glob(os.path.join(temp_dir, "*"))
                downloaded_files = [f for f in downloaded_files if os.path.isfile(f)]
            
            if not downloaded_files:
                return {
                    'success': False,
                    'error': 'FiÈ™ierul nu a fost gÄƒsit dupÄƒ descÄƒrcare',
                    'title': title
                }
            
            # Ia primul fiÈ™ier gÄƒsit (ar trebui sÄƒ fie singurul)
            downloaded_file = downloaded_files[0]
            
            # VerificÄƒ dimensiunea fiÈ™ierului
            file_size = os.path.getsize(downloaded_file)
            max_size = 550 * 1024 * 1024  # 550MB Ã®n bytes

            if file_size > max_size:
                os.remove(downloaded_file)
                size_mb = file_size / (1024*1024) if isinstance(file_size, (int, float)) else 0
                return {
                    'success': False,
                    'error': f'FiÈ™ierul este prea mare ({size_mb:.1f}MB). Limita este 550MB.',
                    'title': title
                }
            
            return {
                 'success': True,
                 'file_path': downloaded_file,
                 'title': title,
                 'description': description,
                 'uploader': uploader,
                 'duration': duration,
                 'file_size': file_size
             }
            
    except yt_dlp.DownloadError as e:
        error_msg = str(e).lower()
        
        # Gestionare specificÄƒ pentru YouTube HTTP 429
        if ('youtube' in url.lower() or 'youtu.be' in url.lower()) and ('429' in error_msg or 'too many requests' in error_msg or ('rate' in error_msg and 'limit' in error_msg)):
            return {
                'success': False,
                'error': 'âŒ YouTube: Prea multe cereri. YouTube a limitat temporar accesul.\n\nğŸ’¡ SoluÈ›ii:\nâ€¢ ÃncearcÄƒ din nou Ã®n 10-15 minute\nâ€¢ FoloseÈ™te un VPN dacÄƒ problema persistÄƒ\nâ€¢ VerificÄƒ cÄƒ link-ul este valid È™i public',
                'title': 'N/A'
            }
        elif 'rate' in error_msg and 'limit' in error_msg:
            return {
                'success': False,
                'error': 'âŒ Instagram/TikTok: LimitÄƒ de ratÄƒ atinsÄƒ. ÃncearcÄƒ din nou Ã®n cÃ¢teva minute.',
                'title': 'N/A'
            }
        elif 'login' in error_msg or 'authentication' in error_msg or 'cookies' in error_msg:
            help_msg = '\n\nPentru Instagram: FoloseÈ™te --cookies-from-browser sau --cookies pentru autentificare.'
            help_msg += '\nVezi: https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp'
            return {
                'success': False,
                'error': f'âŒ Instagram/TikTok: ConÈ›inut privat sau necesitÄƒ autentificare.{help_msg}',
                'title': 'N/A'
            }
        elif 'not available' in error_msg:
            return {
                'success': False,
                'error': 'âŒ ConÈ›inutul nu este disponibil sau a fost È™ters.',
                'title': 'N/A'
            }
        elif 'cannot parse data' in error_msg or 'parse' in error_msg:
            return {
                'success': False,
                'error': 'âŒ Facebook: Eroare de parsare a datelor. Acest lucru poate fi cauzat de:\nâ€¢ Emoticoane sau caractere speciale Ã®n titlu\nâ€¢ ConÈ›inut privat sau restricÈ›ionat\nâ€¢ Probleme temporare cu platforma\n\nğŸ’¡ ÃncearcÄƒ din nou Ã®n cÃ¢teva minute.',
                'title': 'N/A'
            }
        elif 'facebook' in error_msg and ('error' in error_msg or 'failed' in error_msg):
            return {
                'success': False,
                'error': 'âŒ Facebook: Eroare la accesarea conÈ›inutului. VerificÄƒ cÄƒ link-ul este public È™i valid.',
                'title': 'N/A'
            }
        else:
            return {
                'success': False,
                'error': f'âŒ Eroare la descÄƒrcare: {str(e)}',
                'title': 'N/A'
            }
    except Exception as e:
        return {
            'success': False,
            'error': f'âŒ Eroare neaÈ™teptatÄƒ: {str(e)}',
            'title': 'N/A'
        }

def is_supported_url(url):
    """
    VerificÄƒ dacÄƒ URL-ul este suportat
    """
    supported_domains = [
        'youtube.com', 'youtu.be', 'tiktok.com', 'instagram.com', 
        'facebook.com', 'fb.watch', 'twitter.com', 'x.com'
    ]
    
    return any(domain in url.lower() for domain in supported_domains)