#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Patch pentru Ã®mbunÄƒtÄƒÈ›irea downloader.py cu soluÈ›ii concrete pentru toate platformele
"""

import os
import sys
import logging
import re
from datetime import datetime

# Configurare logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def apply_enhanced_downloader_patch():
    """AplicÄƒ patch-ul Ã®mbunÄƒtÄƒÈ›it pentru downloader.py"""
    logger.info("ğŸ”§ Aplicare patch Ã®mbunÄƒtÄƒÈ›it pentru downloader.py...")
    
    downloader_path = 'downloader.py'
    
    if not os.path.exists(downloader_path):
        logger.error(f"âŒ FiÈ™ierul {downloader_path} nu existÄƒ!")
        return False
    
    # CiteÈ™te conÈ›inutul actual
    with open(downloader_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Backup
    backup_path = f'downloader.py.backup_enhanced_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
    with open(backup_path, 'w', encoding='utf-8') as f:
        f.write(content)
    logger.info(f"ğŸ“„ Backup creat: {backup_path}")
    
    # 1. ÃmbunÄƒtÄƒÈ›eÈ™te configuraÈ›iile yt-dlp pentru toate platformele
    enhanced_configs = '''
# ConfiguraÈ›ii Ã®mbunÄƒtÄƒÈ›ite pentru toate platformele
ENHANCED_PLATFORM_CONFIGS = {
    'tiktok': {
        'user_agents': [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Android 14; Mobile; rv:121.0) Gecko/121.0 Firefox/121.0',
            'Mozilla/5.0 (Linux; Android 14; SM-G998B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 5,
            'fragment_retries': 5,
            'extractor_retries': 3,
            'socket_timeout': 30,
            'sleep_interval': 2,
            'max_sleep_interval': 10,
            'geo_bypass': True,
            'nocheckcertificate': True,
            'extractor_args': {
                'tiktok': {
                    'webpage_download_timeout': 30,
                    'api_hostname': 'api.tiktokv.com'
                }
            }
        }
    },
    'instagram': {
        'user_agents': [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True,
            'extractor_args': {
                'instagram': {
                    'api_version': 'v19.0',
                    'include_stories': False
                }
            }
        }
    },
    'reddit': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 5,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True
        }
    },
    'facebook': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 5,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True,
            'extractor_args': {
                'facebook': {
                    'api_version': 'v19.0',
                    'legacy_ssl': True,
                    'tab': 'videos'
                }
            }
        }
    },
    'twitter': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True
        }
    },
    'vimeo': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True
        }
    },
    'dailymotion': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True
        }
    },
    'pinterest': {
        'user_agents': [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True
        }
    },
    'threads': {
        'user_agents': [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ],
        'ydl_opts_extra': {
            'http_chunk_size': 10485760,
            'retries': 3,
            'socket_timeout': 30,
            'geo_bypass': True,
            'nocheckcertificate': True,
            'extractor_args': {
                'instagram': {  # Threads foloseÈ™te Instagram extractor
                    'api_version': 'v19.0'
                }
            }
        }
    }
}

def get_platform_from_url(url):
    """DeterminÄƒ platforma din URL"""
    url_lower = url.lower()
    
    if any(domain in url_lower for domain in ['tiktok.com', 'vm.tiktok.com']):
        return 'tiktok'
    elif 'instagram.com' in url_lower:
        return 'instagram'
    elif any(domain in url_lower for domain in ['reddit.com', 'redd.it', 'v.redd.it']):
        return 'reddit'
    elif any(domain in url_lower for domain in ['facebook.com', 'fb.watch', 'fb.me']):
        return 'facebook'
    elif any(domain in url_lower for domain in ['twitter.com', 'x.com']):
        return 'twitter'
    elif 'vimeo.com' in url_lower:
        return 'vimeo'
    elif any(domain in url_lower for domain in ['dailymotion.com', 'dai.ly']):
        return 'dailymotion'
    elif any(domain in url_lower for domain in ['pinterest.com', 'pin.it']):
        return 'pinterest'
    elif 'threads.net' in url_lower:
        return 'threads'
    
    return 'generic'

def create_enhanced_ydl_opts(url, temp_dir):
    """CreeazÄƒ opÈ›iuni yt-dlp Ã®mbunÄƒtÄƒÈ›ite bazate pe platformÄƒ"""
    platform = get_platform_from_url(url)
    config = ENHANCED_PLATFORM_CONFIGS.get(platform, {})
    
    # OpÈ›iuni de bazÄƒ
    ydl_opts = {
        'format': 'best[filesize<45M][height<=720]/best[height<=720]/best',
        'outtmpl': os.path.join(temp_dir, '%(title)s.%(ext)s'),
        'restrictfilenames': True,
        'noplaylist': True,
        'extract_flat': False,
        'writethumbnail': False,
        'writeinfojson': False,
        'no_warnings': False,
        'ignoreerrors': False,
        'prefer_free_formats': False,
        'max_filesize': 50 * 1024 * 1024,  # 50MB
        'max_duration': 600,  # 10 minutes
        'http_headers': get_random_headers()
    }
    
    # AdaugÄƒ configuraÈ›ii specifice platformei
    if config.get('ydl_opts_extra'):
        ydl_opts.update(config['ydl_opts_extra'])
    
    # SeteazÄƒ user agent aleatoriu din lista platformei
    if config.get('user_agents'):
        import random
        user_agent = random.choice(config['user_agents'])
        ydl_opts['http_headers']['User-Agent'] = user_agent
    
    return ydl_opts

def download_with_enhanced_retry(url, temp_dir, max_attempts=3):
    """DescarcÄƒ cu strategii Ã®mbunÄƒtÄƒÈ›ite de retry"""
    platform = get_platform_from_url(url)
    config = ENHANCED_PLATFORM_CONFIGS.get(platform, {})
    
    last_error = None
    
    for attempt in range(max_attempts):
        try:
            logger.info(f"ğŸ”„ Ãncercare {attempt + 1}/{max_attempts} pentru {platform}...")
            
            # CreeazÄƒ opÈ›iuni Ã®mbunÄƒtÄƒÈ›ite
            ydl_opts = create_enhanced_ydl_opts(url, temp_dir)
            
            # AdaugÄƒ delay Ã®ntre Ã®ncercÄƒri
            if attempt > 0:
                import time
                delay = 2 ** attempt  # Exponential backoff
                logger.info(f"â±ï¸ AÈ™teptare {delay}s Ã®nainte de Ã®ncercarea {attempt + 1}...")
                time.sleep(delay)
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # Extrage informaÈ›ii
                info = ydl.extract_info(url, download=False)
                if not info:
                    raise Exception("Nu s-au putut extrage informaÈ›iile video")
                
                # VerificÄƒ dacÄƒ este live stream
                if info.get('is_live'):
                    raise Exception("Live stream-urile nu sunt suportate")
                
                # DescarcÄƒ videoclipul
                ydl.download([url])
                
                # GÄƒseÈ™te fiÈ™ierul descÄƒrcat
                downloaded_files = []
                for file in os.listdir(temp_dir):
                    if file.endswith(('.mp4', '.mkv', '.webm', '.avi', '.mov', '.flv', '.3gp')):
                        downloaded_files.append(os.path.join(temp_dir, file))
                
                if not downloaded_files:
                    raise Exception("Nu s-a gÄƒsit fiÈ™ierul video descÄƒrcat")
                
                video_file = downloaded_files[0]
                file_size = os.path.getsize(video_file)
                
                logger.info(f"âœ… DescÄƒrcare reuÈ™itÄƒ pentru {platform} la Ã®ncercarea {attempt + 1}")
                
                return {
                    'success': True,
                    'file_path': video_file,
                    'title': info.get('title', 'Video'),
                    'description': info.get('description', ''),
                    'uploader': info.get('uploader', ''),
                    'duration': info.get('duration', 0),
                    'file_size': file_size,
                    'platform': platform,
                    'attempt_number': attempt + 1
                }
                
        except Exception as e:
            error_msg = str(e)
            last_error = error_msg
            logger.warning(f"âŒ Ãncercarea {attempt + 1} eÈ™uatÄƒ pentru {platform}: {error_msg[:100]}...")
            
            # VerificÄƒ dacÄƒ este o eroare criticÄƒ care nu meritÄƒ retry
            critical_errors = [
                'private video', 'video unavailable', 'video not found',
                'this video is private', 'content not available',
                'video has been removed', 'account suspended'
            ]
            
            if any(critical in error_msg.lower() for critical in critical_errors):
                logger.info(f"ğŸ›‘ Eroare criticÄƒ detectatÄƒ, oprire retry pentru {platform}")
                break
    
    return {
        'success': False,
        'error': f'âŒ {platform.title()}: Toate Ã®ncercÄƒrile au eÈ™uat. Ultima eroare: {last_error}',
        'file_path': None,
        'file_size': 0,
        'duration': 0,
        'title': f'{platform.title()} - EÈ™ec descÄƒrcare',
        'platform': platform,
        'total_attempts': max_attempts
    }

'''
    
    # GÄƒseÈ™te locaÈ›ia unde sÄƒ insereze configuraÈ›iile
    insert_pos = content.find('# Lista de User Agents reali')
    if insert_pos == -1:
        insert_pos = content.find('REAL_USER_AGENTS = [')
    
    if insert_pos != -1:
        content = content[:insert_pos] + enhanced_configs + '\n\n' + content[insert_pos:]
        logger.info("âœ… ConfiguraÈ›ii Ã®mbunÄƒtÄƒÈ›ite adÄƒugate")
    else:
        logger.warning("âš ï¸ Nu s-a gÄƒsit locaÈ›ia pentru configuraÈ›ii, adÄƒugare la sfÃ¢rÈ™itul fiÈ™ierului")
        content += '\n\n' + enhanced_configs
    
    # 2. ÃmbunÄƒtÄƒÈ›eÈ™te funcÈ›ia download_video
    download_function_pattern = r'(def download_video\([^)]+\):[^\n]*\n)(\s+)"""[^"]*"""\n'
    download_match = re.search(download_function_pattern, content, re.DOTALL)
    
    if download_match:
        indent = download_match.group(2)
        enhanced_download_start = f'''{download_match.group(1)}{download_match.group(2)}"""\n{indent}DescarcÄƒ un video cu strategii Ã®mbunÄƒtÄƒÈ›ite pentru toate platformele\n{indent}ReturneazÄƒ un dicÈ›ionar cu rezultatul\n{indent}"""\n{indent}logger.info(f"=== ENHANCED DOWNLOAD_VIDEO START === URL: {{url}}")\n{indent}\n{indent}try:\n{indent}    # ValideazÄƒ URL-ul Ã®nainte de procesare\n{indent}    logger.info(f"=== ENHANCED DOWNLOAD_VIDEO Validating URL ===")\n{indent}    is_valid, validation_msg = validate_url(url)\n{indent}    if not is_valid:\n{indent}        logger.error(f"=== ENHANCED DOWNLOAD_VIDEO URL Invalid === {{validation_msg}}")\n{indent}        return {{\n{indent}            'success': False,\n{indent}            'error': f'âŒ URL invalid: {{validation_msg}}',\n{indent}            'title': 'N/A'\n{indent}        }}\n{indent}\n{indent}    # CreeazÄƒ directorul temporar\n{indent}    temp_dir = validate_and_create_temp_dir()\n{indent}    if not temp_dir:\n{indent}        return {{\n{indent}            'success': False,\n{indent}            'error': 'âŒ Nu s-a putut crea directorul temporar',\n{indent}            'title': 'N/A'\n{indent}        }}\n{indent}\n{indent}    logger.info(f"=== ENHANCED DOWNLOAD_VIDEO Temp dir created: {{temp_dir}} ===")\n{indent}\n{indent}    # FoloseÈ™te strategia Ã®mbunÄƒtÄƒÈ›itÄƒ de descÄƒrcare\n{indent}    result = download_with_enhanced_retry(url, temp_dir, max_attempts=3)\n{indent}    \n{indent}    if result['success']:\n{indent}        logger.info(f"âœ… ENHANCED DOWNLOAD SUCCESS: {{result['title']}}")\n{indent}    else:\n{indent}        logger.error(f"âŒ ENHANCED DOWNLOAD FAILED: {{result['error']}}")\n{indent}    \n{indent}    return result\n{indent}\n{indent}except Exception as e:\n{indent}    logger.error(f"=== ENHANCED DOWNLOAD_VIDEO Exception === {{str(e)}}")\n{indent}    import traceback\n{indent}    logger.error(f"=== ENHANCED DOWNLOAD_VIDEO Traceback === {{traceback.format_exc()}}")\n{indent}    return {{\n{indent}        'success': False,\n{indent}        'error': f'âŒ Eroare neaÈ™teptatÄƒ: {{str(e)}}',\n{indent}        'title': 'N/A'\n{indent}    }}\n{indent}\n{indent}finally:\n{indent}    # Nu È™terge temp_dir aici - va fi È™ters dupÄƒ trimiterea fiÈ™ierului\n{indent}    pass\n\n'''
        
        # ÃnlocuieÈ™te funcÈ›ia download_video existentÄƒ
        old_function_end = content.find('finally:', download_match.end())
        if old_function_end != -1:
            # GÄƒseÈ™te sfÃ¢rÈ™itul funcÈ›iei
            lines = content[old_function_end:].split('\n')
            function_end = old_function_end
            for i, line in enumerate(lines):
                if line and not line.startswith(' ') and not line.startswith('\t') and i > 0:
                    function_end = old_function_end + len('\n'.join(lines[:i]))
                    break
            else:
                function_end = len(content)
            
            content = content[:download_match.start()] + enhanced_download_start + content[function_end:]
            logger.info("âœ… FuncÈ›ia download_video Ã®mbunÄƒtÄƒÈ›itÄƒ")
        else:
            logger.warning("âš ï¸ Nu s-a putut gÄƒsi sfÃ¢rÈ™itul funcÈ›iei download_video")
    else:
        logger.warning("âš ï¸ Nu s-a gÄƒsit funcÈ›ia download_video")
    
    # 3. AdaugÄƒ funcÈ›ii de suport pentru URL variants
    url_variants_functions = '''
def get_url_variants(url):
    """GenereazÄƒ variante de URL pentru Ã®ncercÄƒri multiple"""
    platform = get_platform_from_url(url)
    variants = [url]  # URL original
    
    if platform == 'facebook':
        # Variante Facebook
        if '/watch?v=' in url:
            video_id = url.split('/watch?v=')[1].split('&')[0]
            variants.extend([
                f"https://www.facebook.com/share/v/{video_id}/",
                f"https://m.facebook.com/watch?v={video_id}",
                f"https://fb.watch/{video_id}"
            ])
        elif '/share/v/' in url:
            video_id = url.split('/share/v/')[1].split('/')[0]
            variants.extend([
                f"https://www.facebook.com/watch?v={video_id}",
                f"https://m.facebook.com/watch?v={video_id}"
            ])
    
    elif platform == 'twitter':
        # Variante Twitter/X
        variants.extend([
            url.replace('twitter.com', 'x.com'),
            url.replace('x.com', 'twitter.com'),
            url.replace('mobile.twitter.com', 'twitter.com')
        ])
    
    elif platform == 'dailymotion':
        # Variante Dailymotion
        if 'dai.ly/' in url:
            video_id = url.split('dai.ly/')[1]
            variants.append(f"https://www.dailymotion.com/video/{video_id}")
        elif 'dailymotion.com/video/' in url:
            video_id = url.split('/video/')[1].split('?')[0]
            variants.append(f"https://dai.ly/{video_id}")
    
    elif platform == 'pinterest':
        # Variante Pinterest
        if 'pin.it/' in url:
            # Pentru pin.it, Ã®ncercÄƒm sÄƒ gÄƒsim ID-ul real
            variants.append(url.replace('pin.it/', 'pinterest.com/pin/'))
    
    # EliminÄƒ duplicatele È™i returneazÄƒ
    return list(dict.fromkeys(variants))

def normalize_url_for_platform(url):
    """NormalizeazÄƒ URL-ul pentru platformÄƒ"""
    platform = get_platform_from_url(url)
    
    if platform == 'reddit':
        # EliminÄƒ parametrii de query pentru Reddit
        url = url.split('?')[0].rstrip('/')
        # AsigurÄƒ-te cÄƒ nu se terminÄƒ cu .json
        if url.endswith('.json'):
            url = url[:-5]
    
    elif platform == 'tiktok':
        # NormalizeazÄƒ TikTok URLs
        if 'vm.tiktok.com' in url:
            # Pentru link-uri scurte, le lÄƒsÄƒm aÈ™a cum sunt
            pass
        else:
            # EliminÄƒ parametrii extra
            url = url.split('?')[0]
    
    elif platform == 'instagram':
        # NormalizeazÄƒ Instagram URLs
        url = url.split('?')[0].rstrip('/')
    
    return url

'''
    
    # AdaugÄƒ funcÈ›iile de suport
    content += '\n\n' + url_variants_functions
    logger.info("âœ… FuncÈ›ii de suport pentru URL variants adÄƒugate")
    
    # SalveazÄƒ fiÈ™ierul modificat
    with open(downloader_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"âœ… Patch Ã®mbunÄƒtÄƒÈ›it aplicat cu succes Ã®n {downloader_path}")
    return True

def main():
    """FuncÈ›ia principalÄƒ"""
    logger.info(f"ğŸš€ Ãncepere aplicare patch Ã®mbunÄƒtÄƒÈ›it la {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        success = apply_enhanced_downloader_patch()
        
        if success:
            logger.info("\n" + "="*60)
            logger.info("âœ… PATCH ÃMBUNÄ‚TÄ‚ÈšIT APLICAT CU SUCCES!")
            logger.info("="*60)
            logger.info("\nğŸ¯ ÃmbunÄƒtÄƒÈ›iri implementate:")
            logger.info("  1. âœ… ConfiguraÈ›ii optimizate pentru toate platformele")
            logger.info("  2. âœ… Strategii de retry Ã®mbunÄƒtÄƒÈ›ite")
            logger.info("  3. âœ… User-agent rotation per platformÄƒ")
            logger.info("  4. âœ… Gestionare Ã®mbunÄƒtÄƒÈ›itÄƒ a erorilor")
            logger.info("  5. âœ… URL normalization È™i variants")
            logger.info("  6. âœ… Timeout-uri È™i retry logic optimizate")
            logger.info("  7. âœ… Geo-bypass È™i SSL bypass pentru toate platformele")
            logger.info("\nğŸ”„ UrmÄƒtorii paÈ™i:")
            logger.info("  1. TesteazÄƒ din nou toate platformele")
            logger.info("  2. VerificÄƒ Ã®mbunÄƒtÄƒÈ›irile Ã®n acÈ›iune")
            logger.info("  3. MonitorizeazÄƒ rata de succes")
            return 0
        else:
            logger.error("âŒ Aplicarea patch-ului a eÈ™uat")
            return 1
            
    except Exception as e:
        logger.error(f"âŒ Eroare Ã®n timpul aplicÄƒrii patch-ului: {str(e)}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return 1

if __name__ == "__main__":
    sys.exit(main())